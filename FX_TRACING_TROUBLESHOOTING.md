# FX Tracing Troubleshooting Guide

## ğŸš¨ Lá»—i thÆ°á»ng gáº·p

### Lá»—i: "Detected that you are using FX to symbolically trace a dynamo-optimized function"

```
RuntimeError: Detected that you are using FX to symbolically trace a dynamo-optimized function. This is not supported at the moment.
```

**NguyÃªn nhÃ¢n:** Xung Ä‘á»™t giá»¯a TorchDynamo vÃ  FX symbolic tracing trong Unsloth.

## ğŸ”§ Giáº£i phÃ¡p

### 1. Kiá»ƒm tra Compatibility
```bash
make check-compatibility
```

### 2. Sá»­ dá»¥ng Compatible Evaluation
```bash
make evaluate-llm-compatible
```

### 3. CÃ¡c tÃ¹y chá»n khÃ¡c

#### A. Safe Evaluation
```bash
make evaluate-llm-safe
```

#### B. Fast Evaluation (khÃ´ng cÃ³ progress tracking)
```bash
make evaluate-llm-fast
```

## ğŸ’¡ Tá»± Ä‘á»™ng xá»­ lÃ½

Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ tá»± Ä‘á»™ng xá»­ lÃ½ lá»—i FX tracing:

1. **Táº¯t TorchDynamo** - `torch._dynamo.config.disable = True`
2. **Set Environment Variables** - `TORCH_COMPILE_DISABLE=1`
3. **Safe Model Loading** - Sá»­ dá»¥ng cáº¥u hÃ¬nh an toÃ n
4. **Safe Inference Mode** - `FastModel.for_inference(model)`

## ğŸ“Š Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng

### Environment Variables
```bash
TOKENIZERS_PARALLELISM=false
TORCH_COMPILE_DISABLE=1
TORCH_LOGS=off
CUDA_LAUNCH_BLOCKING=1
```

### TorchDynamo Configuration
```python
torch._dynamo.config.suppress_errors = True
torch._dynamo.config.disable = True
```

### Model Loading
```python
FastModel.from_pretrained(
    # ... other params
    device_map="auto"  # Safe device mapping
)
```

## ğŸ› ï¸ Commands há»¯u Ã­ch

```bash
# Kiá»ƒm tra compatibility
make check-compatibility

# Compatible evaluation
make evaluate-llm-compatible

# Safe evaluation
make evaluate-llm-safe

# Fast evaluation (khÃ´ng progress tracking)
make evaluate-llm-fast

# Quick evaluation (5 samples)
make evaluate-llm-quick
```

## ğŸ” Debug Tips

### 1. Check PyTorch Version
```bash
python3 -c "import torch; print(torch.__version__)"
```

### 2. Check Unsloth Version
```bash
python3 -c "import unsloth; print(unsloth.__version__)"
```

### 3. Monitor System Resources
```bash
htop
```

### 4. Check GPU Memory
```bash
nvidia-smi
```

## ğŸ“ Log Messages

Há»‡ thá»‘ng sáº½ hiá»ƒn thá»‹ cÃ¡c log messages sau:

```
âœ… TorchDynamo disabled
âœ… FX tracing conflicts prevented
âœ… Model loaded successfully with GPU (safe mode)
âœ… Model prepared for inference (safe mode)
```

## ğŸ¯ Best Practices

1. **LuÃ´n cháº¡y `make check-compatibility` trÆ°á»›c khi evaluation**
2. **Sá»­ dá»¥ng `make evaluate-llm-compatible` cho láº§n Ä‘áº§u**
3. **Monitor logs cho báº¥t ká»³ lá»—i nÃ o**
4. **Äáº£m báº£o PyTorch vÃ  Unsloth versions tÆ°Æ¡ng thÃ­ch**
5. **Sá»­ dá»¥ng safe mode khi cÃ³ váº¥n Ä‘á»**

## ğŸ”§ Manual Fixes

### Náº¿u váº«n gáº·p lá»—i, thá»­ cÃ¡c bÆ°á»›c sau:

1. **Restart Python process**
2. **Clear PyTorch cache**
   ```python
   import torch
   torch.cuda.empty_cache()
   ```

3. **Set environment variables manually**
   ```bash
   export TORCH_COMPILE_DISABLE=1
   export TORCH_LOGS=off
   ```

4. **Use CPU-only mode**
   ```python
   device_map="cpu"
   ```

## ğŸ†˜ Náº¿u váº«n gáº·p lá»—i

1. **Check logs chi tiáº¿t**
2. **Verify PyTorch/Unsloth versions**
3. **Try different quantization settings**
4. **Consider using standard transformers instead of Unsloth**
5. **Contact support vá»›i logs Ä‘áº§y Ä‘á»§**

## ğŸ“‹ Version Compatibility

### Recommended Versions
- **PyTorch**: 2.2+ (2.1 may have issues)
- **Unsloth**: Latest version
- **Transformers**: Compatible with Unsloth

### Known Issues
- PyTorch 2.1 + Unsloth: May have FX tracing conflicts
- Older PyTorch versions: Not supported by Unsloth
- Mixed precision: May cause issues with some configurations
