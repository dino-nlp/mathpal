{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e947f242",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d8fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dino/.cache/pypoetry/virtualenvs/mathpal-EU7lYW5B-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a734707",
   "metadata": {},
   "source": [
    "## IMAGE PROCESSING UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e637d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url: str, timeout: int = 10) -> Optional[Image.Image]:\n",
    "    \"\"\"\n",
    "    Download and convert URL to PIL Image.\n",
    "\n",
    "    Args:\n",
    "        url: Image URL\n",
    "        timeout: Request timeout in seconds\n",
    "\n",
    "    Returns:\n",
    "        PIL Image object or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        image = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
    "        return image\n",
    "    except (requests.exceptions.RequestException, IOError) as e:\n",
    "        print(f\"Failed to load image from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_image_urls_from_markdown(text: str) -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Extract image URLs from markdown text and replace with placeholders.\n",
    "\n",
    "    Args:\n",
    "        text: Markdown text containing image links\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (cleaned_text, list_of_image_urls)\n",
    "    \"\"\"\n",
    "    # Pattern for markdown images: ![alt](url)\n",
    "    image_pattern = r\"!\\[.*?\\]\\((.*?)\\)\"\n",
    "    image_urls = re.findall(image_pattern, text)\n",
    "\n",
    "    # Remove image markdown syntax\n",
    "    cleaned_text = re.sub(image_pattern, \" \", text).strip()\n",
    "\n",
    "    return cleaned_text, image_urls\n",
    "\n",
    "def process_markdown_for_model(text: str) -> Tuple[str, List[Image.Image]]:\n",
    "    \"\"\"\n",
    "    Process markdown text to extract text and images for multimodal model.\n",
    "\n",
    "    Args:\n",
    "        text: Input markdown text\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (processed_text, list_of_pil_images)\n",
    "    \"\"\"\n",
    "    cleaned_text, image_urls = extract_image_urls_from_markdown(text)\n",
    "\n",
    "    # Download images\n",
    "    images = []\n",
    "    for url in image_urls:\n",
    "        image = url_to_image(url)\n",
    "        if image:\n",
    "            images.append(image)\n",
    "        else:\n",
    "            print(f\"Warning: Failed to load image from {url}\")\n",
    "\n",
    "    return cleaned_text, images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d1327d",
   "metadata": {},
   "source": [
    "## DATASET PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfdb5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversation_content(text: str, images: List[Image.Image]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Create conversation content list with text and images.\n",
    "\n",
    "    Args:\n",
    "        text: Text content\n",
    "        images: List of PIL images\n",
    "\n",
    "    Returns:\n",
    "        List of content dictionaries\n",
    "    \"\"\"\n",
    "    content = [{\"type\": \"text\", \"text\": text}]\n",
    "\n",
    "    # Add images\n",
    "    for image in images:\n",
    "        content.append({\"type\": \"image\", \"image\": image})\n",
    "\n",
    "    return content\n",
    "\n",
    "def process_math_sample(sample: Dict[str, str]) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Process a single math problem sample into conversation format.\n",
    "\n",
    "    Args:\n",
    "        sample: Dataset sample with 'question' and 'solution' keys\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with 'conversations' key containing the formatted conversation\n",
    "    \"\"\"\n",
    "    # Process question\n",
    "    question_text, question_images = process_markdown_for_model(sample[\"question\"])\n",
    "    user_content = create_conversation_content(question_text, question_images)\n",
    "\n",
    "    # Process solution (usually text-only, but check for images)\n",
    "    solution_text, solution_images = process_markdown_for_model(sample[\"solution\"])\n",
    "    assistant_content = create_conversation_content(solution_text, solution_images)\n",
    "\n",
    "    # Create conversation\n",
    "    conversations = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": assistant_content\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def prepare_dataset(dataset_name: str, split: str) -> Dataset:\n",
    "    \"\"\"\n",
    "    Load and prepare the math dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: HuggingFace dataset name\n",
    "        split: Dataset split to load\n",
    "\n",
    "    Returns:\n",
    "        Processed Dataset object\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset: {dataset_name}, split: {split}\")\n",
    "    raw_dataset = load_dataset(dataset_name, split=split)\n",
    "\n",
    "    print(f\"Processing {len(raw_dataset)} samples...\")\n",
    "    processed_data = []\n",
    "\n",
    "    for i, sample in enumerate(raw_dataset):\n",
    "        try:\n",
    "            processed_sample = process_math_sample(sample)\n",
    "            processed_data.append(processed_sample)\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Processed {i + 1}/{len(raw_dataset)} samples\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Successfully processed {len(processed_data)} samples\")\n",
    "    return Dataset.from_list(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3f708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"ngohongthai/exam-sixth_grade-instruct-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54caf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset(dataset_name, \"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathpal-EU7lYW5B-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
