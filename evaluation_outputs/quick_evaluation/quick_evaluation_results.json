{
  "experiment_name": "quick_evaluation",
  "model_path": "unsloth/gemma-3n-E2B-it",
  "metrics": {
    "answer_relevance_metric": 0.6999999999999998,
    "UsefulnessMetric": 0.4666666666666666,
    "mathematical_accuracy": 0.5,
    "vietnamese_language_quality": 0.5,
    "accuracy": 0.0,
    "completeness": 0.0,
    "clarity": 0.0,
    "relevance": 0.0,
    "helpfulness": 0.0,
    "overall_score": 0.2333333333333333
  },
  "metadata": {
    "config": {
      "experiment_name": "quick_evaluation",
      "output_dir": "./evaluation_outputs",
      "model": "unsloth/gemma-3n-E2B-it",
      "dataset": "ngohongthai/exam-sixth_grade-instruct-dataset",
      "evaluation_mode": "comprehensive",
      "max_samples": 3
    },
    "system_info": {
      "device_info": {
        "cuda_available": true,
        "device_count": 1,
        "current_device": "cuda:0",
        "device_name": "NVIDIA GeForce RTX 3070",
        "memory_info": {
          "cuda:0": {
            "total": 8589410304,
            "allocated": 0,
            "cached": 0
          }
        }
      },
      "environment_variables": {
        "OPENROUTER_API_KEY": "sk-or-v1...",
        "OPENAI_API_KEY": "sk-proj-...",
        "PYTHONPATH": "/home/dino/workdpace/mathpal/src",
        "PWD": "/home/dino/workdpace/mathpal"
      },
      "hardware_config": {
        "device": "auto",
        "memory_efficient": true,
        "memory_fraction": 0.9,
        "gradient_checkpointing": true,
        "optimize_for": "auto"
      },
      "performance_config": {
        "enable_profiling": false,
        "profile_output": "profiles/evaluation_profile.json",
        "enable_metrics": false,
        "metrics_port": 8000
      }
    },
    "dataset_info": {
      "source": "huggingface",
      "id": "ngohongthai/exam-sixth_grade-instruct-dataset",
      "split": "test",
      "info": {}
    }
  },
  "samples_evaluated": 3,
  "evaluation_time": 121.60259795188904,
  "output_path": "evaluation_outputs/quick_evaluation"
}