# GPU Memory Troubleshooting Guide

## ğŸš¨ Lá»—i thÆ°á»ng gáº·p

### Lá»—i: "Some modules are dispatched on the CPU or the disk"

```
ValueError: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model.
```

**NguyÃªn nhÃ¢n:** KhÃ´ng Ä‘á»§ GPU RAM Ä‘á»ƒ load model quantized.

## ğŸ”§ Giáº£i phÃ¡p

### 1. Kiá»ƒm tra GPU Memory
```bash
make check-gpu
```

### 2. Sá»­ dá»¥ng Safe Evaluation
```bash
make evaluate-llm-safe
```

### 3. CÃ¡c tÃ¹y chá»n khÃ¡c

#### A. Fast Evaluation (khÃ´ng cÃ³ progress tracking)
```bash
make evaluate-llm-fast
```

#### B. Quick Evaluation (chá»‰ 5 samples)
```bash
make evaluate-llm-quick
```

#### C. Custom Evaluation vá»›i Ã­t samples
```bash
make evaluate-llm-custom SAMPLES=3 EXPERIMENT="Quick Test"
```

## ğŸ’¡ Tá»± Ä‘á»™ng xá»­ lÃ½

Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ tá»± Ä‘á»™ng xá»­ lÃ½ lá»—i GPU memory:

1. **Thá»­ GPU first** - Load model vá»›i GPU
2. **CPU Offload** - Náº¿u GPU khÃ´ng Ä‘á»§, sá»­ dá»¥ng CPU offload
3. **8-bit Quantization** - Náº¿u 4-bit khÃ´ng work, thá»­ 8-bit
4. **No Quantization** - Cuá»‘i cÃ¹ng, load khÃ´ng cÃ³ quantization

## ğŸ“Š Memory Requirements

### Gemma-3N Model
- **4-bit quantization**: ~4-6 GB GPU RAM
- **8-bit quantization**: ~8-12 GB GPU RAM
- **No quantization**: ~16-24 GB GPU RAM

### Recommendations
- **< 8 GB GPU RAM**: Sá»­ dá»¥ng CPU offload
- **8-16 GB GPU RAM**: Sá»­ dá»¥ng 4-bit quantization
- **> 16 GB GPU RAM**: Standard loading

## ğŸ› ï¸ Commands há»¯u Ã­ch

```bash
# Kiá»ƒm tra GPU memory
make check-gpu

# Safe evaluation vá»›i memory check
make evaluate-llm-safe

# Fast evaluation (khÃ´ng progress tracking)
make evaluate-llm-fast

# Quick evaluation (5 samples)
make evaluate-llm-quick

# Custom evaluation
make evaluate-llm-custom SAMPLES=3 EXPERIMENT="Test"
```

## ğŸ” Debug Tips

### 1. Monitor GPU Memory
```bash
watch -n 1 nvidia-smi
```

### 2. Clear GPU Cache
```bash
python3 -c "import torch; torch.cuda.empty_cache()"
```

### 3. Check System Resources
```bash
htop
```

## ğŸ“ Log Messages

Há»‡ thá»‘ng sáº½ hiá»ƒn thá»‹ cÃ¡c log messages sau:

```
ğŸ”„ Attempting to load model with GPU...
âœ… Model loaded successfully with GPU

# Hoáº·c náº¿u GPU khÃ´ng Ä‘á»§:
âš ï¸  GPU RAM insufficient, attempting CPU offload...
âœ… Model loaded successfully with CPU offload

# Hoáº·c náº¿u cáº§n 8-bit:
ğŸ”„ Attempting to load with 8-bit quantization...
âœ… Model loaded successfully with 8-bit quantization
```

## ğŸ¯ Best Practices

1. **LuÃ´n cháº¡y `make check-gpu` trÆ°á»›c khi evaluation**
2. **Sá»­ dá»¥ng `make evaluate-llm-safe` cho láº§n Ä‘áº§u**
3. **Monitor memory usage trong quÃ¡ trÃ¬nh evaluation**
4. **ÄÃ³ng cÃ¡c á»©ng dá»¥ng khÃ¡c sá»­ dá»¥ng GPU**
5. **Sá»­ dá»¥ng smaller model náº¿u cÃ³ thá»ƒ**

## ğŸ†˜ Náº¿u váº«n gáº·p lá»—i

1. **Kiá»ƒm tra logs chi tiáº¿t**
2. **Thá»­ vá»›i Ã­t samples hÆ¡n**
3. **Restart system Ä‘á»ƒ clear memory**
4. **Consider using CPU-only mode**
5. **Contact support vá»›i logs Ä‘áº§y Ä‘á»§**
