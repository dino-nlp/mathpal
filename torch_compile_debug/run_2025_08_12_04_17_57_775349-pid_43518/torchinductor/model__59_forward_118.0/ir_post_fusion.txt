op0: NopKernelSchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', d1, {d0: 0, d1: 0})]
op0.unmet_dependencies = []
op0.met_dependencies = []
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
    buf0.users = [
        NodeUser(node=SchedulerNode(name='op1'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op2'), can_inplace=True, is_weak=False),
    ]
]


op4: SchedulerNode(ComputedBuffer)
op4.writes = [MemoryDep('buf4', c0, {c0: 2048*(((s3 + 8)//9))})]
op4.unmet_dependencies = []
op4.met_dependencies = [MemoryDep('primals_7', c0, {c0: 2048*(((s3 + 8)//9))})]
op4.outputs = [
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf4.users = [NodeUser(node=ExternKernelSchedulerNode(name='op5'), can_inplace=False, is_weak=False)]
]
op4.group.device = cuda:0
op4.group.iteration = (2048*(((s3 + 8)//9)), 1)
op4.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf4_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op4_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf4', get_index_1, to_dtype, None)
        return store


op12: SchedulerNode(ComputedBuffer)
op12.writes = [MemoryDep('buf12', c0, {c0: 2048*(((s3 + 8)//9))})]
op12.unmet_dependencies = []
op12.met_dependencies = [MemoryDep('primals_7', c0 + 2048*(((s3 + 8)//9)), {c0: 2048*(((s3 + 8)//9))})]
op12.outputs = [
    buf12: ComputedBuffer
    buf12.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf12.users = [NodeUser(node=ExternKernelSchedulerNode(name='op13'), can_inplace=False, is_weak=False)]
]
op12.group.device = cuda:0
op12.group.iteration = (2048*(((s3 + 8)//9)), 1)
op12.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf12_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op12_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0 + 2048*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf12', get_index_1, to_dtype, None)
        return store


op20: SchedulerNode(ComputedBuffer)
op20.writes = [MemoryDep('buf20', c0, {c0: 2048*(((s3 + 8)//9))})]
op20.unmet_dependencies = []
op20.met_dependencies = [MemoryDep('primals_7', c0 + 4096*(((s3 + 8)//9)), {c0: 2048*(((s3 + 8)//9))})]
op20.outputs = [
    buf20: ComputedBuffer
    buf20.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf20.users = [NodeUser(node=ExternKernelSchedulerNode(name='op21'), can_inplace=False, is_weak=False)]
]
op20.group.device = cuda:0
op20.group.iteration = (2048*(((s3 + 8)//9)), 1)
op20.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf20_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op20_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0 + 4096*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf20', get_index_1, to_dtype, None)
        return store


op28: SchedulerNode(ComputedBuffer)
op28.writes = [MemoryDep('buf28', c0, {c0: 2048*(((s3 + 8)//9))})]
op28.unmet_dependencies = []
op28.met_dependencies = [MemoryDep('primals_7', c0 + 6144*(((s3 + 8)//9)), {c0: 2048*(((s3 + 8)//9))})]
op28.outputs = [
    buf28: ComputedBuffer
    buf28.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf28.users = [NodeUser(node=ExternKernelSchedulerNode(name='op29'), can_inplace=False, is_weak=False)]
]
op28.group.device = cuda:0
op28.group.iteration = (2048*(((s3 + 8)//9)), 1)
op28.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf28_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op28_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0 + 6144*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf28', get_index_1, to_dtype, None)
        return store


op36: SchedulerNode(ComputedBuffer)
op36.writes = [MemoryDep('buf36', c0, {c0: 2048*(((s3 + 8)//9))})]
op36.unmet_dependencies = []
op36.met_dependencies = [MemoryDep('primals_7', c0 + 8192*(((s3 + 8)//9)), {c0: 2048*(((s3 + 8)//9))})]
op36.outputs = [
    buf36: ComputedBuffer
    buf36.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf36.users = [NodeUser(node=ExternKernelSchedulerNode(name='op37'), can_inplace=False, is_weak=False)]
]
op36.group.device = cuda:0
op36.group.iteration = (2048*(((s3 + 8)//9)), 1)
op36.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf36_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op36_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0 + 8192*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf36', get_index_1, to_dtype, None)
        return store


op44: SchedulerNode(ComputedBuffer)
op44.writes = [MemoryDep('buf44', c0, {c0: 2048*(((s3 + 8)//9))})]
op44.unmet_dependencies = []
op44.met_dependencies = [MemoryDep('primals_7', c0 + 10240*(((s3 + 8)//9)), {c0: 2048*(((s3 + 8)//9))})]
op44.outputs = [
    buf44: ComputedBuffer
    buf44.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf44.users = [NodeUser(node=ExternKernelSchedulerNode(name='op45'), can_inplace=False, is_weak=False)]
]
op44.group.device = cuda:0
op44.group.iteration = (2048*(((s3 + 8)//9)), 1)
op44.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf44_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op44_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0 + 10240*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf44', get_index_1, to_dtype, None)
        return store


op52: SchedulerNode(ComputedBuffer)
op52.writes = [MemoryDep('buf52', c0, {c0: 2048*(((s3 + 8)//9))})]
op52.unmet_dependencies = []
op52.met_dependencies = [MemoryDep('primals_7', c0 + 12288*(((s3 + 8)//9)), {c0: 2048*(((s3 + 8)//9))})]
op52.outputs = [
    buf52: ComputedBuffer
    buf52.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf52.users = [NodeUser(node=ExternKernelSchedulerNode(name='op53'), can_inplace=False, is_weak=False)]
]
op52.group.device = cuda:0
op52.group.iteration = (2048*(((s3 + 8)//9)), 1)
op52.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf52_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op52_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0 + 12288*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf52', get_index_1, to_dtype, None)
        return store


op60: SchedulerNode(ComputedBuffer)
op60.writes = [MemoryDep('buf60', c0, {c0: 2048*(((s3 + 8)//9))})]
op60.unmet_dependencies = []
op60.met_dependencies = [MemoryDep('primals_7', c0 + 14336*(((s3 + 8)//9)), {c0: 2048*(((s3 + 8)//9))})]
op60.outputs = [
    buf60: ComputedBuffer
    buf60.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
    buf60.users = [NodeUser(node=ExternKernelSchedulerNode(name='op61'), can_inplace=False, is_weak=False)]
]
op60.group.device = cuda:0
op60.group.iteration = (2048*(((s3 + 8)//9)), 1)
op60.sizes = ([2048*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf60_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 2048], stride=[2048, 1])
class op60_loop_body:
    var_ranges = {p0: 2048*(((s3 + 8)//9))}
    index0 = p0 + 14336*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf60', get_index_1, to_dtype, None)
        return store


op68: SchedulerNode(ComputedBuffer)
op68.writes = [MemoryDep('buf68', c0, {c0: 2048*s3 - 16384*(((s3 + 8)//9))})]
op68.unmet_dependencies = []
op68.met_dependencies = [   MemoryDep('primals_7', c0 + 16384*(((s3 + 8)//9)), {c0: 2048*s3 - 16384*(((s3 + 8)//9))})]
op68.outputs = [
    buf68: ComputedBuffer
    buf68.layout = FixedLayout('cuda:0', torch.bfloat16, size=[s3 - 8*(((s3 + 8)//9)), 2048], stride=[2048, 1])
    buf68.users = [NodeUser(node=ExternKernelSchedulerNode(name='op69'), can_inplace=False, is_weak=False)]
]
op68.group.device = cuda:0
op68.group.iteration = (2048*s3 - 16384*(((s3 + 8)//9)), 1)
op68.sizes = ([2048*s3 - 16384*(((s3 + 8)//9))], [])
primals_7_layout = FixedLayout('cuda:0', torch.float32, size=[1, s3, 2048], stride=[2048*s3, 2048, 1])
buf68_layout = FixedLayout('cuda:0', torch.bfloat16, size=[s3 - 8*(((s3 + 8)//9)), 2048], stride=[2048, 1])
class op68_loop_body:
    var_ranges = {p0: 2048*s3 - 16384*(((s3 + 8)//9))}
    index0 = p0 + 16384*(((s3 + 8)//9))
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_7', get_index)
        to_dtype = ops.to_dtype(load, torch.bfloat16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf68', get_index_1, to_dtype, None)
        return store


op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: s0})]
op1.unmet_dependencies = [MemoryDep('buf0', c0, {c0: s0})]
op1.met_dependencies = [MemoryDep('primals_3', c0 + 1, {c0: s0})]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
    buf1.users = [NodeUser(node=SchedulerNode(name='op3'), can_inplace=False, is_weak=False)]
]
op1.group.device = cuda:0
op1.group.iteration = (s0, 1)
op1.sizes = ([s0], [])
primals_3_layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
buf0_layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
buf1_layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
class op1_loop_body:
    var_ranges = {p0: s0}
    index0 = p0
    index1 = s0 - 1
    index2 = p0 + 1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        lt = ops.lt(index_expr, index_expr_1)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_2 = self.get_index('index0')
        load = ops.load('buf0', get_index_2)
        where = ops.where(lt, masked_subblock1, load)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf1', get_index_3, where, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('primals_3', get_index)
        return load


op2_op3: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op2_op3.writes = [MemoryDep('buf2', c0, {c0: s0 - 1}), MemoryDep('buf3', c0, {c0: s0 - 1})]
op2_op3.unmet_dependencies = [MemoryDep('buf0', c0, {c0: s0 - 1}), StarDep(name='buf1', mode=None)]
op2_op3.met_dependencies = 
    [   MemoryDep('primals_3', c0 + 1, {c0: s0 - 1}),
        MemoryDep('primals_5', c0 + 1, {c0: s0 - 1})]
op2_op3.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda:0', torch.int64, size=[1, s1 - 1], stride=[s1 - 1, 1])
    buf2.users = [NodeUser(node=SchedulerNode(name='op3'), can_inplace=True, is_weak=False)]
    buf3: ComputedBuffer
    buf3.layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
    buf3.mutations = ['buf1']
    buf3.users = [
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op35'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op51'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op59'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op67'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op75'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op77'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op78'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op79'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op80'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op81'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op82'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op83'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op84'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op85'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op86'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op87'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op88'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op89'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op90'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op91'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op92'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op93'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op94'), can_inplace=True, is_weak=False),
    ]
]
op2_op3.snodes[0] =
op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', c0, {c0: s0 - 1})]
op2.unmet_dependencies = [MemoryDep('buf0', c0, {c0: s0 - 1})]
op2.met_dependencies = 
    [   MemoryDep('primals_3', c0 + 1, {c0: s0 - 1}),
        MemoryDep('primals_5', c0 + 1, {c0: s0 - 1})]
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda:0', torch.int64, size=[1, s1 - 1], stride=[s1 - 1, 1])
    buf2.users = [NodeUser(node=SchedulerNode(name='op3'), can_inplace=True, is_weak=False)]
]
op2.group.device = cuda:0
op2.group.iteration = (s0 - 1, 1)
op2.sizes = ([s0 - 1], [])
primals_5_layout = FixedLayout('cuda:0', torch.int64, size=[1, s1], stride=[s1, 1])
primals_3_layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
buf0_layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
buf2_layout = FixedLayout('cuda:0', torch.int64, size=[1, s1 - 1], stride=[s1 - 1, 1])
class op2_loop_body:
    var_ranges = {p0: s0 - 1}
    index0 = p0 + 1
    index1 = p0
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_5', get_index)
        constant = ops.constant(0, torch.int64)
        eq = ops.eq(load, constant)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int64)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int64)
        lt = ops.lt(index_expr, index_expr_1)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_3 = self.get_index('index1')
        load_1 = ops.load('buf0', get_index_3)
        where = ops.where(lt, masked_subblock1, load_1)
        constant_1 = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant_1, where)
        get_index_4 = self.get_index('index1')
        store = ops.store('buf2', get_index_4, where_1, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_3', get_index)
        return load
op2_op3.snodes[1] =
op3: SchedulerNode(ComputedBuffer)
op3.writes = [MemoryDep('buf3', c0, {c0: s0 - 1})]
op3.unmet_dependencies = [MemoryDep('buf2', c0, {c0: s0 - 1}), StarDep(name='buf1', mode=None)]
op3.met_dependencies = []
op3.outputs = [
    buf3: ComputedBuffer
    buf3.layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
    buf3.mutations = ['buf1']
    buf3.users = [
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op35'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op51'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op59'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op67'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op75'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op77'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op78'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op79'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op80'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op81'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op82'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op83'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op84'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op85'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op86'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op87'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op88'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op89'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op90'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op91'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op92'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op93'), can_inplace=True, is_weak=False),
        NodeUser(node=SchedulerNode(name='op94'), can_inplace=True, is_weak=False),
    ]
]
op3.group.device = cuda:0
op3.group.iteration = (s0 - 1, 1)
op3.sizes = ([s0 - 1], [])
buf2_layout = FixedLayout('cuda:0', torch.int64, size=[1, s1 - 1], stride=[s1 - 1, 1])
buf1_layout = FixedLayout('cuda:0', torch.int64, size=[1, s0], stride=[s0, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
class op3_loop_body:
    var_ranges = {p0: s0 - 1}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf2', get_index)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf3', get_index_1, load, None)
        return store


op5: ExternKernelSchedulerNode(ExternKernelOut)
op5.writes = [StarDep(name='buf5', mode=None)]
op5.unmet_dependencies = [StarDep(name='buf4', mode=None)]
op5.met_dependencies = [StarDep(name='primals_1', mode=None)]
op5.outputs = [
    buf5: ExternKernelOut
    buf5.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf5.users = [
        NodeUser(node=SchedulerNode(name='op6'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op8'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op5.node.kernel = extern_kernels.mm


op13: ExternKernelSchedulerNode(ExternKernelOut)
op13.writes = [StarDep(name='buf13', mode=None)]
op13.unmet_dependencies = [StarDep(name='buf12', mode=None)]
op13.met_dependencies = [StarDep(name='primals_1', mode=None)]
op13.outputs = [
    buf13: ExternKernelOut
    buf13.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf13.users = [
        NodeUser(node=SchedulerNode(name='op14'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op16'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op13.node.kernel = extern_kernels.mm


op21: ExternKernelSchedulerNode(ExternKernelOut)
op21.writes = [StarDep(name='buf21', mode=None)]
op21.unmet_dependencies = [StarDep(name='buf20', mode=None)]
op21.met_dependencies = [StarDep(name='primals_1', mode=None)]
op21.outputs = [
    buf21: ExternKernelOut
    buf21.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf21.users = [
        NodeUser(node=SchedulerNode(name='op22'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op24'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op21.node.kernel = extern_kernels.mm


op29: ExternKernelSchedulerNode(ExternKernelOut)
op29.writes = [StarDep(name='buf29', mode=None)]
op29.unmet_dependencies = [StarDep(name='buf28', mode=None)]
op29.met_dependencies = [StarDep(name='primals_1', mode=None)]
op29.outputs = [
    buf29: ExternKernelOut
    buf29.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf29.users = [
        NodeUser(node=SchedulerNode(name='op30'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op32'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op35'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op29.node.kernel = extern_kernels.mm


op37: ExternKernelSchedulerNode(ExternKernelOut)
op37.writes = [StarDep(name='buf37', mode=None)]
op37.unmet_dependencies = [StarDep(name='buf36', mode=None)]
op37.met_dependencies = [StarDep(name='primals_1', mode=None)]
op37.outputs = [
    buf37: ExternKernelOut
    buf37.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf37.users = [
        NodeUser(node=SchedulerNode(name='op38'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op40'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op37.node.kernel = extern_kernels.mm


op45: ExternKernelSchedulerNode(ExternKernelOut)
op45.writes = [StarDep(name='buf45', mode=None)]
op45.unmet_dependencies = [StarDep(name='buf44', mode=None)]
op45.met_dependencies = [StarDep(name='primals_1', mode=None)]
op45.outputs = [
    buf45: ExternKernelOut
    buf45.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf45.users = [
        NodeUser(node=SchedulerNode(name='op46'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op48'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op51'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op45.node.kernel = extern_kernels.mm


op53: ExternKernelSchedulerNode(ExternKernelOut)
op53.writes = [StarDep(name='buf53', mode=None)]
op53.unmet_dependencies = [StarDep(name='buf52', mode=None)]
op53.met_dependencies = [StarDep(name='primals_1', mode=None)]
op53.outputs = [
    buf53: ExternKernelOut
    buf53.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf53.users = [
        NodeUser(node=SchedulerNode(name='op54'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op56'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op59'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op53.node.kernel = extern_kernels.mm


op61: ExternKernelSchedulerNode(ExternKernelOut)
op61.writes = [StarDep(name='buf61', mode=None)]
op61.unmet_dependencies = [StarDep(name='buf60', mode=None)]
op61.met_dependencies = [StarDep(name='primals_1', mode=None)]
op61.outputs = [
    buf61: ExternKernelOut
    buf61.layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
    buf61.users = [
        NodeUser(node=SchedulerNode(name='op62'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op64'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op67'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op61.node.kernel = extern_kernels.mm


op69: ExternKernelSchedulerNode(ExternKernelOut)
op69.writes = [StarDep(name='buf69', mode=None)]
op69.unmet_dependencies = [StarDep(name='buf68', mode=None)]
op69.met_dependencies = [StarDep(name='primals_1', mode=None)]
op69.outputs = [
    buf69: ExternKernelOut
    buf69.layout = FixedLayout('cuda:0', torch.bfloat16, size=[s3 - 8*(((s3 + 8)//9)), 262400], stride=[262400, 1])
    buf69.users = [
        NodeUser(node=SchedulerNode(name='op70'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op72'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op75'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op69.node.kernel = extern_kernels.mm


op91_op92: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op91_op92.writes = 
    [   MemoryDep('buf91', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf92', c0, {c0: ((s0 + 8)//9)})]
op91_op92.unmet_dependencies = [MemoryDep('buf3', c0 + (((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op91_op92.met_dependencies = []
op91_op92.outputs = [
    buf91: ComputedBuffer
    buf91.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf91.users = [
        NodeUser(node=SchedulerNode(name='op92'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf92: ComputedBuffer
    buf92.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf92.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op91_op92.snodes[0] =
op91: SchedulerNode(ComputedBuffer)
op91.writes = [MemoryDep('buf91', c0, {c0: ((s0 + 8)//9)})]
op91.unmet_dependencies = [MemoryDep('buf3', c0 + (((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op91.met_dependencies = []
op91.outputs = [
    buf91: ComputedBuffer
    buf91.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf91.users = [
        NodeUser(node=SchedulerNode(name='op92'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op91.group.device = cuda:0
op91.group.iteration = (((s0 + 8)//9), 1)
op91.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf91_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op91_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + (((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf91', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op91_op92.snodes[1] =
op92: SchedulerNode(ComputedBuffer)
op92.writes = [MemoryDep('buf92', c0, {c0: ((s0 + 8)//9)})]
op92.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + (((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf91', c0, {c0: ((s0 + 8)//9)})]
op92.met_dependencies = []
op92.outputs = [
    buf92: ComputedBuffer
    buf92.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf92.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op92.group.device = cuda:0
op92.group.iteration = (((s0 + 8)//9), 1)
op92.sizes = ([((s0 + 8)//9)], [])
buf91_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf92_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op92_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = p0 + (((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf91', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf92', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load


op93_op94: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op93_op94.writes = 
    [   MemoryDep('buf93', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf94', c0, {c0: ((s0 + 8)//9)})]
op93_op94.unmet_dependencies = [MemoryDep('buf3', c0, {c0: ((s0 + 8)//9)})]
op93_op94.met_dependencies = []
op93_op94.outputs = [
    buf93: ComputedBuffer
    buf93.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf93.users = [
        NodeUser(node=SchedulerNode(name='op94'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf94: ComputedBuffer
    buf94.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf94.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op93_op94.snodes[0] =
op93: SchedulerNode(ComputedBuffer)
op93.writes = [MemoryDep('buf93', c0, {c0: ((s0 + 8)//9)})]
op93.unmet_dependencies = [MemoryDep('buf3', c0, {c0: ((s0 + 8)//9)})]
op93.met_dependencies = []
op93.outputs = [
    buf93: ComputedBuffer
    buf93.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf93.users = [
        NodeUser(node=SchedulerNode(name='op94'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op93.group.device = cuda:0
op93.group.iteration = (((s0 + 8)//9), 1)
op93.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf93_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op93_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf93', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op93_op94.snodes[1] =
op94: SchedulerNode(ComputedBuffer)
op94.writes = [MemoryDep('buf94', c0, {c0: ((s0 + 8)//9)})]
op94.unmet_dependencies = 
    [   MemoryDep('buf3', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf93', c0, {c0: ((s0 + 8)//9)})]
op94.met_dependencies = []
op94.outputs = [
    buf94: ComputedBuffer
    buf94.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf94.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op94.group.device = cuda:0
op94.group.iteration = (((s0 + 8)//9), 1)
op94.sizes = ([((s0 + 8)//9)], [])
buf93_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf94_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op94_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf93', get_index)
        get_index_1 = self.get_index('index0')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf94', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load


op6: SchedulerNode(ComputedBuffer)
op6.writes = [MemoryDep('buf6', c0, {c0: 5*(((s3 + 8)//9))})]
op6.unmet_dependencies = [MemoryDep('buf5', c0, {c0: 262400*(((s3 + 8)//9))})]
op6.met_dependencies = []
op6.outputs = [
    buf6: ComputedBuffer
    buf6.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf6.users = [NodeUser(node=SchedulerNode(name='op7'), can_inplace=False, is_weak=False)]
]
op6.group.device = cuda:0
op6.group.iteration = (5*(((s3 + 8)//9)), 52480)
op6.sizes = ([5*(((s3 + 8)//9))], [52480])
buf5_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf6_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op6_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf5', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf6', get_index_1, reduction)
        return store_reduction


op14: SchedulerNode(ComputedBuffer)
op14.writes = [MemoryDep('buf14', c0, {c0: 5*(((s3 + 8)//9))})]
op14.unmet_dependencies = [MemoryDep('buf13', c0, {c0: 262400*(((s3 + 8)//9))})]
op14.met_dependencies = []
op14.outputs = [
    buf14: ComputedBuffer
    buf14.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf14.users = [NodeUser(node=SchedulerNode(name='op15'), can_inplace=False, is_weak=False)]
]
op14.group.device = cuda:0
op14.group.iteration = (5*(((s3 + 8)//9)), 52480)
op14.sizes = ([5*(((s3 + 8)//9))], [52480])
buf13_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf14_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op14_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf13', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf14', get_index_1, reduction)
        return store_reduction


op22: SchedulerNode(ComputedBuffer)
op22.writes = [MemoryDep('buf22', c0, {c0: 5*(((s3 + 8)//9))})]
op22.unmet_dependencies = [MemoryDep('buf21', c0, {c0: 262400*(((s3 + 8)//9))})]
op22.met_dependencies = []
op22.outputs = [
    buf22: ComputedBuffer
    buf22.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf22.users = [NodeUser(node=SchedulerNode(name='op23'), can_inplace=False, is_weak=False)]
]
op22.group.device = cuda:0
op22.group.iteration = (5*(((s3 + 8)//9)), 52480)
op22.sizes = ([5*(((s3 + 8)//9))], [52480])
buf21_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf22_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op22_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf21', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf22', get_index_1, reduction)
        return store_reduction


op30: SchedulerNode(ComputedBuffer)
op30.writes = [MemoryDep('buf30', c0, {c0: 5*(((s3 + 8)//9))})]
op30.unmet_dependencies = [MemoryDep('buf29', c0, {c0: 262400*(((s3 + 8)//9))})]
op30.met_dependencies = []
op30.outputs = [
    buf30: ComputedBuffer
    buf30.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf30.users = [NodeUser(node=SchedulerNode(name='op31'), can_inplace=False, is_weak=False)]
]
op30.group.device = cuda:0
op30.group.iteration = (5*(((s3 + 8)//9)), 52480)
op30.sizes = ([5*(((s3 + 8)//9))], [52480])
buf29_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf30_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op30_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf29', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf30', get_index_1, reduction)
        return store_reduction


op38: SchedulerNode(ComputedBuffer)
op38.writes = [MemoryDep('buf38', c0, {c0: 5*(((s3 + 8)//9))})]
op38.unmet_dependencies = [MemoryDep('buf37', c0, {c0: 262400*(((s3 + 8)//9))})]
op38.met_dependencies = []
op38.outputs = [
    buf38: ComputedBuffer
    buf38.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf38.users = [NodeUser(node=SchedulerNode(name='op39'), can_inplace=False, is_weak=False)]
]
op38.group.device = cuda:0
op38.group.iteration = (5*(((s3 + 8)//9)), 52480)
op38.sizes = ([5*(((s3 + 8)//9))], [52480])
buf37_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf38_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op38_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf37', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf38', get_index_1, reduction)
        return store_reduction


op46: SchedulerNode(ComputedBuffer)
op46.writes = [MemoryDep('buf46', c0, {c0: 5*(((s3 + 8)//9))})]
op46.unmet_dependencies = [MemoryDep('buf45', c0, {c0: 262400*(((s3 + 8)//9))})]
op46.met_dependencies = []
op46.outputs = [
    buf46: ComputedBuffer
    buf46.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf46.users = [NodeUser(node=SchedulerNode(name='op47'), can_inplace=False, is_weak=False)]
]
op46.group.device = cuda:0
op46.group.iteration = (5*(((s3 + 8)//9)), 52480)
op46.sizes = ([5*(((s3 + 8)//9))], [52480])
buf45_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf46_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op46_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf45', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf46', get_index_1, reduction)
        return store_reduction


op54: SchedulerNode(ComputedBuffer)
op54.writes = [MemoryDep('buf54', c0, {c0: 5*(((s3 + 8)//9))})]
op54.unmet_dependencies = [MemoryDep('buf53', c0, {c0: 262400*(((s3 + 8)//9))})]
op54.met_dependencies = []
op54.outputs = [
    buf54: ComputedBuffer
    buf54.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf54.users = [NodeUser(node=SchedulerNode(name='op55'), can_inplace=False, is_weak=False)]
]
op54.group.device = cuda:0
op54.group.iteration = (5*(((s3 + 8)//9)), 52480)
op54.sizes = ([5*(((s3 + 8)//9))], [52480])
buf53_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf54_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op54_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf53', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf54', get_index_1, reduction)
        return store_reduction


op62: SchedulerNode(ComputedBuffer)
op62.writes = [MemoryDep('buf62', c0, {c0: 5*(((s3 + 8)//9))})]
op62.unmet_dependencies = [MemoryDep('buf61', c0, {c0: 262400*(((s3 + 8)//9))})]
op62.met_dependencies = []
op62.outputs = [
    buf62: ComputedBuffer
    buf62.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf62.users = [NodeUser(node=SchedulerNode(name='op63'), can_inplace=False, is_weak=False)]
]
op62.group.device = cuda:0
op62.group.iteration = (5*(((s3 + 8)//9)), 52480)
op62.sizes = ([5*(((s3 + 8)//9))], [52480])
buf61_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf62_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op62_loop_body:
    var_ranges = {p0: 5*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf61', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf62', get_index_1, reduction)
        return store_reduction


op70: SchedulerNode(ComputedBuffer)
op70.writes = [MemoryDep('buf70', c0, {c0: 5*s3 - 40*(((s3 + 8)//9))})]
op70.unmet_dependencies = [MemoryDep('buf69', c0, {c0: 262400*s3 - 2099200*(((s3 + 8)//9))})]
op70.met_dependencies = []
op70.outputs = [
    buf70: ComputedBuffer
    buf70.layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1, 5], stride=[5, 5*s3 - 40*(((s3 + 8)//9)), 1])
    buf70.users = [NodeUser(node=SchedulerNode(name='op71'), can_inplace=False, is_weak=False)]
]
op70.group.device = cuda:0
op70.group.iteration = (5*s3 - 40*(((s3 + 8)//9)), 52480)
op70.sizes = ([5*s3 - 40*(((s3 + 8)//9))], [52480])
buf69_layout = FixedLayout('cuda:0', torch.bfloat16, size=[s3 - 8*(((s3 + 8)//9)), 262400], stride=[262400, 1])
buf70_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1, 5], stride=[5, 5*s3 - 40*(((s3 + 8)//9)), 1])
class op70_loop_body:
    var_ranges = {p0: 5*s3 - 40*(((s3 + 8)//9)), p1: 52480}
    index0 = 52480*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf69', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', mul_1)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf70', get_index_1, reduction)
        return store_reduction


op7: SchedulerNode(ComputedBuffer)
op7.writes = [MemoryDep('buf7', c0, {c0: ((s3 + 8)//9)})]
op7.unmet_dependencies = [MemoryDep('buf6', c0, {c0: 5*(((s3 + 8)//9))})]
op7.met_dependencies = []
op7.outputs = [
    buf7: ComputedBuffer
    buf7.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf7.users = [
        NodeUser(node=SchedulerNode(name='op8'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op7.group.device = cuda:0
op7.group.iteration = (((s3 + 8)//9), 5)
op7.sizes = ([((s3 + 8)//9)], [5])
buf6_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf7_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op7_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf6', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf7', get_index_1, reduction)
        return store_reduction


op8: SchedulerNode(ComputedBuffer)
op8.writes = [MemoryDep('buf8', c0, {c0: 5*(((s3 + 8)//9))})]
op8.unmet_dependencies = 
    [   MemoryDep('buf5', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf7', c0, {c0: ((s3 + 8)//9)})]
op8.met_dependencies = []
op8.outputs = [
    buf8: ComputedBuffer
    buf8.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf8.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=False, is_weak=False)]
]
op8.group.device = cuda:0
op8.group.iteration = (5*(((s3 + 8)//9)), 52480)
op8.sizes = ([((s3 + 8)//9), 5], [52480])
buf5_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf7_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf8_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op8_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf5', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf7', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf8', get_index_2, reduction)
        return store_reduction


op15: SchedulerNode(ComputedBuffer)
op15.writes = [MemoryDep('buf15', c0, {c0: ((s3 + 8)//9)})]
op15.unmet_dependencies = [MemoryDep('buf14', c0, {c0: 5*(((s3 + 8)//9))})]
op15.met_dependencies = []
op15.outputs = [
    buf15: ComputedBuffer
    buf15.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf15.users = [
        NodeUser(node=SchedulerNode(name='op16'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op15.group.device = cuda:0
op15.group.iteration = (((s3 + 8)//9), 5)
op15.sizes = ([((s3 + 8)//9)], [5])
buf14_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf15_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op15_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf14', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf15', get_index_1, reduction)
        return store_reduction


op16: SchedulerNode(ComputedBuffer)
op16.writes = [MemoryDep('buf16', c0, {c0: 5*(((s3 + 8)//9))})]
op16.unmet_dependencies = 
    [   MemoryDep('buf13', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf15', c0, {c0: ((s3 + 8)//9)})]
op16.met_dependencies = []
op16.outputs = [
    buf16: ComputedBuffer
    buf16.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf16.users = [NodeUser(node=SchedulerNode(name='op17'), can_inplace=False, is_weak=False)]
]
op16.group.device = cuda:0
op16.group.iteration = (5*(((s3 + 8)//9)), 52480)
op16.sizes = ([((s3 + 8)//9), 5], [52480])
buf13_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf15_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf16_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op16_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf13', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf15', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf16', get_index_2, reduction)
        return store_reduction


op23: SchedulerNode(ComputedBuffer)
op23.writes = [MemoryDep('buf23', c0, {c0: ((s3 + 8)//9)})]
op23.unmet_dependencies = [MemoryDep('buf22', c0, {c0: 5*(((s3 + 8)//9))})]
op23.met_dependencies = []
op23.outputs = [
    buf23: ComputedBuffer
    buf23.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf23.users = [
        NodeUser(node=SchedulerNode(name='op24'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op23.group.device = cuda:0
op23.group.iteration = (((s3 + 8)//9), 5)
op23.sizes = ([((s3 + 8)//9)], [5])
buf22_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf23_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op23_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf22', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf23', get_index_1, reduction)
        return store_reduction


op24: SchedulerNode(ComputedBuffer)
op24.writes = [MemoryDep('buf24', c0, {c0: 5*(((s3 + 8)//9))})]
op24.unmet_dependencies = 
    [   MemoryDep('buf21', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf23', c0, {c0: ((s3 + 8)//9)})]
op24.met_dependencies = []
op24.outputs = [
    buf24: ComputedBuffer
    buf24.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf24.users = [NodeUser(node=SchedulerNode(name='op25'), can_inplace=False, is_weak=False)]
]
op24.group.device = cuda:0
op24.group.iteration = (5*(((s3 + 8)//9)), 52480)
op24.sizes = ([((s3 + 8)//9), 5], [52480])
buf21_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf23_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf24_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op24_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf21', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf23', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf24', get_index_2, reduction)
        return store_reduction


op31: SchedulerNode(ComputedBuffer)
op31.writes = [MemoryDep('buf31', c0, {c0: ((s3 + 8)//9)})]
op31.unmet_dependencies = [MemoryDep('buf30', c0, {c0: 5*(((s3 + 8)//9))})]
op31.met_dependencies = []
op31.outputs = [
    buf31: ComputedBuffer
    buf31.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf31.users = [
        NodeUser(node=SchedulerNode(name='op32'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op35'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op31.group.device = cuda:0
op31.group.iteration = (((s3 + 8)//9), 5)
op31.sizes = ([((s3 + 8)//9)], [5])
buf30_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf31_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op31_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf30', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf31', get_index_1, reduction)
        return store_reduction


op32: SchedulerNode(ComputedBuffer)
op32.writes = [MemoryDep('buf32', c0, {c0: 5*(((s3 + 8)//9))})]
op32.unmet_dependencies = 
    [   MemoryDep('buf29', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf31', c0, {c0: ((s3 + 8)//9)})]
op32.met_dependencies = []
op32.outputs = [
    buf32: ComputedBuffer
    buf32.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf32.users = [NodeUser(node=SchedulerNode(name='op33'), can_inplace=False, is_weak=False)]
]
op32.group.device = cuda:0
op32.group.iteration = (5*(((s3 + 8)//9)), 52480)
op32.sizes = ([((s3 + 8)//9), 5], [52480])
buf29_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf31_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf32_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op32_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf29', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf31', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf32', get_index_2, reduction)
        return store_reduction


op39: SchedulerNode(ComputedBuffer)
op39.writes = [MemoryDep('buf39', c0, {c0: ((s3 + 8)//9)})]
op39.unmet_dependencies = [MemoryDep('buf38', c0, {c0: 5*(((s3 + 8)//9))})]
op39.met_dependencies = []
op39.outputs = [
    buf39: ComputedBuffer
    buf39.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf39.users = [
        NodeUser(node=SchedulerNode(name='op40'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op39.group.device = cuda:0
op39.group.iteration = (((s3 + 8)//9), 5)
op39.sizes = ([((s3 + 8)//9)], [5])
buf38_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf39_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op39_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf38', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf39', get_index_1, reduction)
        return store_reduction


op40: SchedulerNode(ComputedBuffer)
op40.writes = [MemoryDep('buf40', c0, {c0: 5*(((s3 + 8)//9))})]
op40.unmet_dependencies = 
    [   MemoryDep('buf37', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf39', c0, {c0: ((s3 + 8)//9)})]
op40.met_dependencies = []
op40.outputs = [
    buf40: ComputedBuffer
    buf40.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf40.users = [NodeUser(node=SchedulerNode(name='op41'), can_inplace=False, is_weak=False)]
]
op40.group.device = cuda:0
op40.group.iteration = (5*(((s3 + 8)//9)), 52480)
op40.sizes = ([((s3 + 8)//9), 5], [52480])
buf37_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf39_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf40_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op40_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf37', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf39', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf40', get_index_2, reduction)
        return store_reduction


op47: SchedulerNode(ComputedBuffer)
op47.writes = [MemoryDep('buf47', c0, {c0: ((s3 + 8)//9)})]
op47.unmet_dependencies = [MemoryDep('buf46', c0, {c0: 5*(((s3 + 8)//9))})]
op47.met_dependencies = []
op47.outputs = [
    buf47: ComputedBuffer
    buf47.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf47.users = [
        NodeUser(node=SchedulerNode(name='op48'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op51'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op47.group.device = cuda:0
op47.group.iteration = (((s3 + 8)//9), 5)
op47.sizes = ([((s3 + 8)//9)], [5])
buf46_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf47_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op47_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf46', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf47', get_index_1, reduction)
        return store_reduction


op48: SchedulerNode(ComputedBuffer)
op48.writes = [MemoryDep('buf48', c0, {c0: 5*(((s3 + 8)//9))})]
op48.unmet_dependencies = 
    [   MemoryDep('buf45', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf47', c0, {c0: ((s3 + 8)//9)})]
op48.met_dependencies = []
op48.outputs = [
    buf48: ComputedBuffer
    buf48.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf48.users = [NodeUser(node=SchedulerNode(name='op49'), can_inplace=False, is_weak=False)]
]
op48.group.device = cuda:0
op48.group.iteration = (5*(((s3 + 8)//9)), 52480)
op48.sizes = ([((s3 + 8)//9), 5], [52480])
buf45_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf47_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf48_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op48_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf45', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf47', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf48', get_index_2, reduction)
        return store_reduction


op55: SchedulerNode(ComputedBuffer)
op55.writes = [MemoryDep('buf55', c0, {c0: ((s3 + 8)//9)})]
op55.unmet_dependencies = [MemoryDep('buf54', c0, {c0: 5*(((s3 + 8)//9))})]
op55.met_dependencies = []
op55.outputs = [
    buf55: ComputedBuffer
    buf55.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf55.users = [
        NodeUser(node=SchedulerNode(name='op56'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op59'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op55.group.device = cuda:0
op55.group.iteration = (((s3 + 8)//9), 5)
op55.sizes = ([((s3 + 8)//9)], [5])
buf54_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf55_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op55_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf54', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf55', get_index_1, reduction)
        return store_reduction


op56: SchedulerNode(ComputedBuffer)
op56.writes = [MemoryDep('buf56', c0, {c0: 5*(((s3 + 8)//9))})]
op56.unmet_dependencies = 
    [   MemoryDep('buf53', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf55', c0, {c0: ((s3 + 8)//9)})]
op56.met_dependencies = []
op56.outputs = [
    buf56: ComputedBuffer
    buf56.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf56.users = [NodeUser(node=SchedulerNode(name='op57'), can_inplace=False, is_weak=False)]
]
op56.group.device = cuda:0
op56.group.iteration = (5*(((s3 + 8)//9)), 52480)
op56.sizes = ([((s3 + 8)//9), 5], [52480])
buf53_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf55_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf56_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op56_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf53', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf55', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf56', get_index_2, reduction)
        return store_reduction


op63: SchedulerNode(ComputedBuffer)
op63.writes = [MemoryDep('buf63', c0, {c0: ((s3 + 8)//9)})]
op63.unmet_dependencies = [MemoryDep('buf62', c0, {c0: 5*(((s3 + 8)//9))})]
op63.met_dependencies = []
op63.outputs = [
    buf63: ComputedBuffer
    buf63.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf63.users = [
        NodeUser(node=SchedulerNode(name='op64'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op67'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op63.group.device = cuda:0
op63.group.iteration = (((s3 + 8)//9), 5)
op63.sizes = ([((s3 + 8)//9)], [5])
buf62_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf63_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op63_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf62', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf63', get_index_1, reduction)
        return store_reduction


op64: SchedulerNode(ComputedBuffer)
op64.writes = [MemoryDep('buf64', c0, {c0: 5*(((s3 + 8)//9))})]
op64.unmet_dependencies = 
    [   MemoryDep('buf61', c0, {c0: 262400*(((s3 + 8)//9))}),
        MemoryDep('buf63', c0, {c0: ((s3 + 8)//9)})]
op64.met_dependencies = []
op64.outputs = [
    buf64: ComputedBuffer
    buf64.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
    buf64.users = [NodeUser(node=SchedulerNode(name='op65'), can_inplace=False, is_weak=False)]
]
op64.group.device = cuda:0
op64.group.iteration = (5*(((s3 + 8)//9)), 52480)
op64.sizes = ([((s3 + 8)//9), 5], [52480])
buf61_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf63_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf64_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
class op64_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf61', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf63', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf64', get_index_2, reduction)
        return store_reduction


op71: SchedulerNode(ComputedBuffer)
op71.writes = [MemoryDep('buf71', c0, {c0: s3 - 8*(((s3 + 8)//9))})]
op71.unmet_dependencies = [MemoryDep('buf70', c0, {c0: 5*s3 - 40*(((s3 + 8)//9))})]
op71.met_dependencies = []
op71.outputs = [
    buf71: ComputedBuffer
    buf71.layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
    buf71.users = [
        NodeUser(node=SchedulerNode(name='op72'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op75'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op71.group.device = cuda:0
op71.group.iteration = (s3 - 8*(((s3 + 8)//9)), 5)
op71.sizes = ([s3 - 8*(((s3 + 8)//9))], [5])
buf70_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1, 5], stride=[5, 5*s3 - 40*(((s3 + 8)//9)), 1])
buf71_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
class op71_loop_body:
    var_ranges = {p0: s3 - 8*(((s3 + 8)//9)), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf70', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'max', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf71', get_index_1, reduction)
        return store_reduction


op72: SchedulerNode(ComputedBuffer)
op72.writes = [MemoryDep('buf72', c0, {c0: 5*s3 - 40*(((s3 + 8)//9))})]
op72.unmet_dependencies = 
    [   MemoryDep('buf69', c0, {c0: 262400*s3 - 2099200*(((s3 + 8)//9))}),
        MemoryDep('buf71', c0, {c0: s3 - 8*(((s3 + 8)//9))})]
op72.met_dependencies = []
op72.outputs = [
    buf72: ComputedBuffer
    buf72.layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1, 5], stride=[5, 5*s3 - 40*(((s3 + 8)//9)), 1])
    buf72.users = [NodeUser(node=SchedulerNode(name='op73'), can_inplace=False, is_weak=False)]
]
op72.group.device = cuda:0
op72.group.iteration = (5*s3 - 40*(((s3 + 8)//9)), 52480)
op72.sizes = ([s3 - 8*(((s3 + 8)//9)), 5], [52480])
buf69_layout = FixedLayout('cuda:0', torch.bfloat16, size=[s3 - 8*(((s3 + 8)//9)), 262400], stride=[262400, 1])
buf71_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
buf72_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1, 5], stride=[5, 5*s3 - 40*(((s3 + 8)//9)), 1])
class op72_loop_body:
    var_ranges = {p0: s3 - 8*(((s3 + 8)//9)), p1: 5, p2: 52480}
    index0 = 262400*p0 + 52480*p1 + p2
    index1 = p0
    index2 = 5*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf69', get_index)
        constant = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load, constant)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_1 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_1)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf71', get_index_1)
        sub = ops.sub(mul_1, load_1)
        constant_2 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_2)
        exp = ops.exp(mul_2)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', exp)
        get_index_2 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf72', get_index_2, reduction)
        return store_reduction


op9_op10: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op9_op10.writes = 
    [   MemoryDep('buf10', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf9', c0, {c0: ((s3 + 8)//9)})]
op9_op10.unmet_dependencies = [MemoryDep('buf8', c0, {c0: 5*(((s3 + 8)//9))})]
op9_op10.met_dependencies = []
op9_op10.outputs = [
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf9.users = [NodeUser(node=SchedulerNode(name='op10'), can_inplace=True, is_weak=False)]
    buf10: ComputedBuffer
    buf10.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf10.users = [
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op9_op10.snodes[0] =
op9: SchedulerNode(ComputedBuffer)
op9.writes = [MemoryDep('buf9', c0, {c0: ((s3 + 8)//9)})]
op9.unmet_dependencies = [MemoryDep('buf8', c0, {c0: 5*(((s3 + 8)//9))})]
op9.met_dependencies = []
op9.outputs = [
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf9.users = [NodeUser(node=SchedulerNode(name='op10'), can_inplace=True, is_weak=False)]
]
op9.group.device = cuda:0
op9.group.iteration = (((s3 + 8)//9), 5)
op9.sizes = ([((s3 + 8)//9)], [5])
buf8_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf9_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op9_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf8', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf9', get_index_1, reduction)
        return store_reduction
op9_op10.snodes[1] =
op10: SchedulerNode(ComputedBuffer)
op10.writes = [MemoryDep('buf10', c0, {c0: ((s3 + 8)//9)})]
op10.unmet_dependencies = [MemoryDep('buf9', c0, {c0: ((s3 + 8)//9)})]
op10.met_dependencies = []
op10.outputs = [
    buf10: ComputedBuffer
    buf10.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf10.users = [
        NodeUser(node=SchedulerNode(name='op11'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op10.group.device = cuda:0
op10.group.iteration = (((s3 + 8)//9), 1)
op10.sizes = ([((s3 + 8)//9)], [])
buf9_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf10_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op10_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf9', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf10', get_index_1, log, None)
        return store


op11: SchedulerNode(ComputedBuffer)
op11.writes = [MemoryDep('buf11', 0, {})]
op11.unmet_dependencies = 
    [   MemoryDep('buf10', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf3', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf5', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf7', c0, {c0: ((s0 + 8)//9)})]
op11.met_dependencies = []
op11.outputs = [
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf11.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op11.group.device = cuda:0
op11.group.iteration = (1, ((s0 + 8)//9))
op11.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf5_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf7_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf10_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf11_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op11_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf5', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index0')
        load_4 = ops.load('buf7', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index0')
        load_5 = ops.load('buf10', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index3')
        store_reduction = ops.store_reduction('buf11', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load


op17_op18: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op17_op18.writes = 
    [   MemoryDep('buf17', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf18', c0, {c0: ((s3 + 8)//9)})]
op17_op18.unmet_dependencies = [MemoryDep('buf16', c0, {c0: 5*(((s3 + 8)//9))})]
op17_op18.met_dependencies = []
op17_op18.outputs = [
    buf17: ComputedBuffer
    buf17.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf17.users = [NodeUser(node=SchedulerNode(name='op18'), can_inplace=True, is_weak=False)]
    buf18: ComputedBuffer
    buf18.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf18.users = [
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op17_op18.snodes[0] =
op17: SchedulerNode(ComputedBuffer)
op17.writes = [MemoryDep('buf17', c0, {c0: ((s3 + 8)//9)})]
op17.unmet_dependencies = [MemoryDep('buf16', c0, {c0: 5*(((s3 + 8)//9))})]
op17.met_dependencies = []
op17.outputs = [
    buf17: ComputedBuffer
    buf17.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf17.users = [NodeUser(node=SchedulerNode(name='op18'), can_inplace=True, is_weak=False)]
]
op17.group.device = cuda:0
op17.group.iteration = (((s3 + 8)//9), 5)
op17.sizes = ([((s3 + 8)//9)], [5])
buf16_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf17_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op17_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf16', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf17', get_index_1, reduction)
        return store_reduction
op17_op18.snodes[1] =
op18: SchedulerNode(ComputedBuffer)
op18.writes = [MemoryDep('buf18', c0, {c0: ((s3 + 8)//9)})]
op18.unmet_dependencies = [MemoryDep('buf17', c0, {c0: ((s3 + 8)//9)})]
op18.met_dependencies = []
op18.outputs = [
    buf18: ComputedBuffer
    buf18.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf18.users = [
        NodeUser(node=SchedulerNode(name='op19'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op18.group.device = cuda:0
op18.group.iteration = (((s3 + 8)//9), 1)
op18.sizes = ([((s3 + 8)//9)], [])
buf17_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf18_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op18_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf17', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf18', get_index_1, log, None)
        return store


op19: SchedulerNode(ComputedBuffer)
op19.writes = [MemoryDep('buf19', 0, {})]
op19.unmet_dependencies = 
    [   MemoryDep('buf13', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf15', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf18', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf3', c0 + (((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op19.met_dependencies = []
op19.outputs = [
    buf19: ComputedBuffer
    buf19.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf19.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op19.group.device = cuda:0
op19.group.iteration = (1, ((s0 + 8)//9))
op19.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf13_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf15_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf18_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf19_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op19_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + (((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf13', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf15', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf18', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf19', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load


op25_op26: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op25_op26.writes = 
    [   MemoryDep('buf25', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf26', c0, {c0: ((s3 + 8)//9)})]
op25_op26.unmet_dependencies = [MemoryDep('buf24', c0, {c0: 5*(((s3 + 8)//9))})]
op25_op26.met_dependencies = []
op25_op26.outputs = [
    buf25: ComputedBuffer
    buf25.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf25.users = [NodeUser(node=SchedulerNode(name='op26'), can_inplace=True, is_weak=False)]
    buf26: ComputedBuffer
    buf26.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf26.users = [
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op25_op26.snodes[0] =
op25: SchedulerNode(ComputedBuffer)
op25.writes = [MemoryDep('buf25', c0, {c0: ((s3 + 8)//9)})]
op25.unmet_dependencies = [MemoryDep('buf24', c0, {c0: 5*(((s3 + 8)//9))})]
op25.met_dependencies = []
op25.outputs = [
    buf25: ComputedBuffer
    buf25.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf25.users = [NodeUser(node=SchedulerNode(name='op26'), can_inplace=True, is_weak=False)]
]
op25.group.device = cuda:0
op25.group.iteration = (((s3 + 8)//9), 5)
op25.sizes = ([((s3 + 8)//9)], [5])
buf24_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf25_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op25_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf24', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf25', get_index_1, reduction)
        return store_reduction
op25_op26.snodes[1] =
op26: SchedulerNode(ComputedBuffer)
op26.writes = [MemoryDep('buf26', c0, {c0: ((s3 + 8)//9)})]
op26.unmet_dependencies = [MemoryDep('buf25', c0, {c0: ((s3 + 8)//9)})]
op26.met_dependencies = []
op26.outputs = [
    buf26: ComputedBuffer
    buf26.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf26.users = [
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op26.group.device = cuda:0
op26.group.iteration = (((s3 + 8)//9), 1)
op26.sizes = ([((s3 + 8)//9)], [])
buf25_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf26_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op26_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf25', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf26', get_index_1, log, None)
        return store


op27_op89_op90: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
op27_op89_op90.writes = 
    [   MemoryDep('buf27', 0, {}),
        MemoryDep('buf89', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf90', c0, {c0: ((s0 + 8)//9)})]
op27_op89_op90.unmet_dependencies = 
    [   MemoryDep('buf21', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf23', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf26', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf3', c0 + 2*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op27_op89_op90.met_dependencies = []
op27_op89_op90.outputs = [
    buf27: ComputedBuffer
    buf27.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf27.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
    buf89: ComputedBuffer
    buf89.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf89.users = [
        NodeUser(node=SchedulerNode(name='op90'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf90: ComputedBuffer
    buf90.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf90.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op27_op89_op90.snodes[0] =
op27: SchedulerNode(ComputedBuffer)
op27.writes = [MemoryDep('buf27', 0, {})]
op27.unmet_dependencies = 
    [   MemoryDep('buf21', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf23', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf26', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf3', c0 + 2*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op27.met_dependencies = []
op27.outputs = [
    buf27: ComputedBuffer
    buf27.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf27.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op27.group.device = cuda:0
op27.group.iteration = (1, ((s0 + 8)//9))
op27.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf21_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf23_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf26_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf27_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op27_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 2*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf21', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf23', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf26', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf27', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op27_op89_op90.snodes[1] =
op89: SchedulerNode(ComputedBuffer)
op89.writes = [MemoryDep('buf89', c0, {c0: ((s0 + 8)//9)})]
op89.unmet_dependencies = [MemoryDep('buf3', c0 + 2*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op89.met_dependencies = []
op89.outputs = [
    buf89: ComputedBuffer
    buf89.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf89.users = [
        NodeUser(node=SchedulerNode(name='op90'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op89.group.device = cuda:0
op89.group.iteration = (((s0 + 8)//9), 1)
op89.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf89_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op89_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 2*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf89', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op27_op89_op90.snodes[2] =
op90: SchedulerNode(ComputedBuffer)
op90.writes = [MemoryDep('buf90', c0, {c0: ((s0 + 8)//9)})]
op90.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 2*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf89', c0, {c0: ((s0 + 8)//9)})]
op90.met_dependencies = []
op90.outputs = [
    buf90: ComputedBuffer
    buf90.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf90.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op90.group.device = cuda:0
op90.group.iteration = (((s0 + 8)//9), 1)
op90.sizes = ([((s0 + 8)//9)], [])
buf89_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf90_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op90_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = p0 + 2*(((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf89', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf90', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load


op33_op34: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op33_op34.writes = 
    [   MemoryDep('buf33', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf34', c0, {c0: ((s3 + 8)//9)})]
op33_op34.unmet_dependencies = [MemoryDep('buf32', c0, {c0: 5*(((s3 + 8)//9))})]
op33_op34.met_dependencies = []
op33_op34.outputs = [
    buf33: ComputedBuffer
    buf33.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf33.users = [NodeUser(node=SchedulerNode(name='op34'), can_inplace=True, is_weak=False)]
    buf34: ComputedBuffer
    buf34.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf34.users = [
        NodeUser(node=SchedulerNode(name='op35'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op33_op34.snodes[0] =
op33: SchedulerNode(ComputedBuffer)
op33.writes = [MemoryDep('buf33', c0, {c0: ((s3 + 8)//9)})]
op33.unmet_dependencies = [MemoryDep('buf32', c0, {c0: 5*(((s3 + 8)//9))})]
op33.met_dependencies = []
op33.outputs = [
    buf33: ComputedBuffer
    buf33.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf33.users = [NodeUser(node=SchedulerNode(name='op34'), can_inplace=True, is_weak=False)]
]
op33.group.device = cuda:0
op33.group.iteration = (((s3 + 8)//9), 5)
op33.sizes = ([((s3 + 8)//9)], [5])
buf32_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf33_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op33_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf32', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf33', get_index_1, reduction)
        return store_reduction
op33_op34.snodes[1] =
op34: SchedulerNode(ComputedBuffer)
op34.writes = [MemoryDep('buf34', c0, {c0: ((s3 + 8)//9)})]
op34.unmet_dependencies = [MemoryDep('buf33', c0, {c0: ((s3 + 8)//9)})]
op34.met_dependencies = []
op34.outputs = [
    buf34: ComputedBuffer
    buf34.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf34.users = [
        NodeUser(node=SchedulerNode(name='op35'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op34.group.device = cuda:0
op34.group.iteration = (((s3 + 8)//9), 1)
op34.sizes = ([((s3 + 8)//9)], [])
buf33_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf34_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op34_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf33', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf34', get_index_1, log, None)
        return store


op35_op87_op88: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
op35_op87_op88.writes = 
    [   MemoryDep('buf35', 0, {}),
        MemoryDep('buf87', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf88', c0, {c0: ((s0 + 8)//9)})]
op35_op87_op88.unmet_dependencies = 
    [   MemoryDep('buf29', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf3', c0 + 3*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf31', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf34', c0, {c0: ((s0 + 8)//9)})]
op35_op87_op88.met_dependencies = []
op35_op87_op88.outputs = [
    buf35: ComputedBuffer
    buf35.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf35.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
    buf87: ComputedBuffer
    buf87.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf87.users = [
        NodeUser(node=SchedulerNode(name='op88'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf88: ComputedBuffer
    buf88.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf88.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op35_op87_op88.snodes[0] =
op35: SchedulerNode(ComputedBuffer)
op35.writes = [MemoryDep('buf35', 0, {})]
op35.unmet_dependencies = 
    [   MemoryDep('buf29', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf3', c0 + 3*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf31', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf34', c0, {c0: ((s0 + 8)//9)})]
op35.met_dependencies = []
op35.outputs = [
    buf35: ComputedBuffer
    buf35.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf35.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op35.group.device = cuda:0
op35.group.iteration = (1, ((s0 + 8)//9))
op35.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf29_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf31_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf34_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf35_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op35_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 3*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf29', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf31', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf34', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf35', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op35_op87_op88.snodes[1] =
op87: SchedulerNode(ComputedBuffer)
op87.writes = [MemoryDep('buf87', c0, {c0: ((s0 + 8)//9)})]
op87.unmet_dependencies = [MemoryDep('buf3', c0 + 3*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op87.met_dependencies = []
op87.outputs = [
    buf87: ComputedBuffer
    buf87.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf87.users = [
        NodeUser(node=SchedulerNode(name='op88'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op87.group.device = cuda:0
op87.group.iteration = (((s0 + 8)//9), 1)
op87.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf87_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op87_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 3*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf87', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op35_op87_op88.snodes[2] =
op88: SchedulerNode(ComputedBuffer)
op88.writes = [MemoryDep('buf88', c0, {c0: ((s0 + 8)//9)})]
op88.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 3*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf87', c0, {c0: ((s0 + 8)//9)})]
op88.met_dependencies = []
op88.outputs = [
    buf88: ComputedBuffer
    buf88.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf88.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op88.group.device = cuda:0
op88.group.iteration = (((s0 + 8)//9), 1)
op88.sizes = ([((s0 + 8)//9)], [])
buf87_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf88_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op88_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = p0 + 3*(((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf87', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf88', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load


op41_op42: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op41_op42.writes = 
    [   MemoryDep('buf41', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf42', c0, {c0: ((s3 + 8)//9)})]
op41_op42.unmet_dependencies = [MemoryDep('buf40', c0, {c0: 5*(((s3 + 8)//9))})]
op41_op42.met_dependencies = []
op41_op42.outputs = [
    buf41: ComputedBuffer
    buf41.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf41.users = [NodeUser(node=SchedulerNode(name='op42'), can_inplace=True, is_weak=False)]
    buf42: ComputedBuffer
    buf42.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf42.users = [
        NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op41_op42.snodes[0] =
op41: SchedulerNode(ComputedBuffer)
op41.writes = [MemoryDep('buf41', c0, {c0: ((s3 + 8)//9)})]
op41.unmet_dependencies = [MemoryDep('buf40', c0, {c0: 5*(((s3 + 8)//9))})]
op41.met_dependencies = []
op41.outputs = [
    buf41: ComputedBuffer
    buf41.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf41.users = [NodeUser(node=SchedulerNode(name='op42'), can_inplace=True, is_weak=False)]
]
op41.group.device = cuda:0
op41.group.iteration = (((s3 + 8)//9), 5)
op41.sizes = ([((s3 + 8)//9)], [5])
buf40_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf41_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op41_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf40', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf41', get_index_1, reduction)
        return store_reduction
op41_op42.snodes[1] =
op42: SchedulerNode(ComputedBuffer)
op42.writes = [MemoryDep('buf42', c0, {c0: ((s3 + 8)//9)})]
op42.unmet_dependencies = [MemoryDep('buf41', c0, {c0: ((s3 + 8)//9)})]
op42.met_dependencies = []
op42.outputs = [
    buf42: ComputedBuffer
    buf42.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf42.users = [
        NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op42.group.device = cuda:0
op42.group.iteration = (((s3 + 8)//9), 1)
op42.sizes = ([((s3 + 8)//9)], [])
buf41_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf42_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op42_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf41', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf42', get_index_1, log, None)
        return store


op43_op85_op86: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
op43_op85_op86.writes = 
    [   MemoryDep('buf43', 0, {}),
        MemoryDep('buf85', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf86', c0, {c0: ((s0 + 8)//9)})]
op43_op85_op86.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 4*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf37', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf39', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf42', c0, {c0: ((s0 + 8)//9)})]
op43_op85_op86.met_dependencies = []
op43_op85_op86.outputs = [
    buf43: ComputedBuffer
    buf43.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf43.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
    buf85: ComputedBuffer
    buf85.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf85.users = [
        NodeUser(node=SchedulerNode(name='op86'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf86: ComputedBuffer
    buf86.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf86.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op43_op85_op86.snodes[0] =
op43: SchedulerNode(ComputedBuffer)
op43.writes = [MemoryDep('buf43', 0, {})]
op43.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 4*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf37', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf39', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf42', c0, {c0: ((s0 + 8)//9)})]
op43.met_dependencies = []
op43.outputs = [
    buf43: ComputedBuffer
    buf43.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf43.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op43.group.device = cuda:0
op43.group.iteration = (1, ((s0 + 8)//9))
op43.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf37_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf39_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf42_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf43_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op43_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 4*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf37', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf39', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf42', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf43', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op43_op85_op86.snodes[1] =
op85: SchedulerNode(ComputedBuffer)
op85.writes = [MemoryDep('buf85', c0, {c0: ((s0 + 8)//9)})]
op85.unmet_dependencies = [MemoryDep('buf3', c0 + 4*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op85.met_dependencies = []
op85.outputs = [
    buf85: ComputedBuffer
    buf85.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf85.users = [
        NodeUser(node=SchedulerNode(name='op86'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op85.group.device = cuda:0
op85.group.iteration = (((s0 + 8)//9), 1)
op85.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf85_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op85_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 4*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf85', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op43_op85_op86.snodes[2] =
op86: SchedulerNode(ComputedBuffer)
op86.writes = [MemoryDep('buf86', c0, {c0: ((s0 + 8)//9)})]
op86.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 4*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf85', c0, {c0: ((s0 + 8)//9)})]
op86.met_dependencies = []
op86.outputs = [
    buf86: ComputedBuffer
    buf86.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf86.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op86.group.device = cuda:0
op86.group.iteration = (((s0 + 8)//9), 1)
op86.sizes = ([((s0 + 8)//9)], [])
buf85_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf86_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op86_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = p0 + 4*(((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf85', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf86', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load


op49_op50: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op49_op50.writes = 
    [   MemoryDep('buf49', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf50', c0, {c0: ((s3 + 8)//9)})]
op49_op50.unmet_dependencies = [MemoryDep('buf48', c0, {c0: 5*(((s3 + 8)//9))})]
op49_op50.met_dependencies = []
op49_op50.outputs = [
    buf49: ComputedBuffer
    buf49.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf49.users = [NodeUser(node=SchedulerNode(name='op50'), can_inplace=True, is_weak=False)]
    buf50: ComputedBuffer
    buf50.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf50.users = [
        NodeUser(node=SchedulerNode(name='op51'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op49_op50.snodes[0] =
op49: SchedulerNode(ComputedBuffer)
op49.writes = [MemoryDep('buf49', c0, {c0: ((s3 + 8)//9)})]
op49.unmet_dependencies = [MemoryDep('buf48', c0, {c0: 5*(((s3 + 8)//9))})]
op49.met_dependencies = []
op49.outputs = [
    buf49: ComputedBuffer
    buf49.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf49.users = [NodeUser(node=SchedulerNode(name='op50'), can_inplace=True, is_weak=False)]
]
op49.group.device = cuda:0
op49.group.iteration = (((s3 + 8)//9), 5)
op49.sizes = ([((s3 + 8)//9)], [5])
buf48_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf49_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op49_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf48', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf49', get_index_1, reduction)
        return store_reduction
op49_op50.snodes[1] =
op50: SchedulerNode(ComputedBuffer)
op50.writes = [MemoryDep('buf50', c0, {c0: ((s3 + 8)//9)})]
op50.unmet_dependencies = [MemoryDep('buf49', c0, {c0: ((s3 + 8)//9)})]
op50.met_dependencies = []
op50.outputs = [
    buf50: ComputedBuffer
    buf50.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf50.users = [
        NodeUser(node=SchedulerNode(name='op51'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op50.group.device = cuda:0
op50.group.iteration = (((s3 + 8)//9), 1)
op50.sizes = ([((s3 + 8)//9)], [])
buf49_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf50_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op50_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf49', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf50', get_index_1, log, None)
        return store


op51_op83_op84: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
op51_op83_op84.writes = 
    [   MemoryDep('buf51', 0, {}),
        MemoryDep('buf83', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf84', c0, {c0: ((s0 + 8)//9)})]
op51_op83_op84.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 5*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf45', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf47', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf50', c0, {c0: ((s0 + 8)//9)})]
op51_op83_op84.met_dependencies = []
op51_op83_op84.outputs = [
    buf51: ComputedBuffer
    buf51.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf51.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
    buf83: ComputedBuffer
    buf83.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf83.users = [
        NodeUser(node=SchedulerNode(name='op84'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf84: ComputedBuffer
    buf84.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf84.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op51_op83_op84.snodes[0] =
op51: SchedulerNode(ComputedBuffer)
op51.writes = [MemoryDep('buf51', 0, {})]
op51.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 5*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf45', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf47', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf50', c0, {c0: ((s0 + 8)//9)})]
op51.met_dependencies = []
op51.outputs = [
    buf51: ComputedBuffer
    buf51.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf51.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op51.group.device = cuda:0
op51.group.iteration = (1, ((s0 + 8)//9))
op51.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf45_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf47_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf50_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf51_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op51_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 5*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf45', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf47', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf50', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf51', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op51_op83_op84.snodes[1] =
op83: SchedulerNode(ComputedBuffer)
op83.writes = [MemoryDep('buf83', c0, {c0: ((s0 + 8)//9)})]
op83.unmet_dependencies = [MemoryDep('buf3', c0 + 5*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op83.met_dependencies = []
op83.outputs = [
    buf83: ComputedBuffer
    buf83.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf83.users = [
        NodeUser(node=SchedulerNode(name='op84'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op83.group.device = cuda:0
op83.group.iteration = (((s0 + 8)//9), 1)
op83.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf83_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op83_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 5*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf83', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op51_op83_op84.snodes[2] =
op84: SchedulerNode(ComputedBuffer)
op84.writes = [MemoryDep('buf84', c0, {c0: ((s0 + 8)//9)})]
op84.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 5*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf83', c0, {c0: ((s0 + 8)//9)})]
op84.met_dependencies = []
op84.outputs = [
    buf84: ComputedBuffer
    buf84.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf84.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op84.group.device = cuda:0
op84.group.iteration = (((s0 + 8)//9), 1)
op84.sizes = ([((s0 + 8)//9)], [])
buf83_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf84_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op84_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = p0 + 5*(((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf83', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf84', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load


op57_op58: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op57_op58.writes = 
    [   MemoryDep('buf57', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf58', c0, {c0: ((s3 + 8)//9)})]
op57_op58.unmet_dependencies = [MemoryDep('buf56', c0, {c0: 5*(((s3 + 8)//9))})]
op57_op58.met_dependencies = []
op57_op58.outputs = [
    buf57: ComputedBuffer
    buf57.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf57.users = [NodeUser(node=SchedulerNode(name='op58'), can_inplace=True, is_weak=False)]
    buf58: ComputedBuffer
    buf58.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf58.users = [
        NodeUser(node=SchedulerNode(name='op59'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op57_op58.snodes[0] =
op57: SchedulerNode(ComputedBuffer)
op57.writes = [MemoryDep('buf57', c0, {c0: ((s3 + 8)//9)})]
op57.unmet_dependencies = [MemoryDep('buf56', c0, {c0: 5*(((s3 + 8)//9))})]
op57.met_dependencies = []
op57.outputs = [
    buf57: ComputedBuffer
    buf57.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf57.users = [NodeUser(node=SchedulerNode(name='op58'), can_inplace=True, is_weak=False)]
]
op57.group.device = cuda:0
op57.group.iteration = (((s3 + 8)//9), 5)
op57.sizes = ([((s3 + 8)//9)], [5])
buf56_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf57_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op57_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf56', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf57', get_index_1, reduction)
        return store_reduction
op57_op58.snodes[1] =
op58: SchedulerNode(ComputedBuffer)
op58.writes = [MemoryDep('buf58', c0, {c0: ((s3 + 8)//9)})]
op58.unmet_dependencies = [MemoryDep('buf57', c0, {c0: ((s3 + 8)//9)})]
op58.met_dependencies = []
op58.outputs = [
    buf58: ComputedBuffer
    buf58.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf58.users = [
        NodeUser(node=SchedulerNode(name='op59'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op58.group.device = cuda:0
op58.group.iteration = (((s3 + 8)//9), 1)
op58.sizes = ([((s3 + 8)//9)], [])
buf57_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf58_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op58_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf57', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf58', get_index_1, log, None)
        return store


op59_op81_op82: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
op59_op81_op82.writes = 
    [   MemoryDep('buf59', 0, {}),
        MemoryDep('buf81', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf82', c0, {c0: ((s0 + 8)//9)})]
op59_op81_op82.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 6*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf53', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf55', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf58', c0, {c0: ((s0 + 8)//9)})]
op59_op81_op82.met_dependencies = []
op59_op81_op82.outputs = [
    buf59: ComputedBuffer
    buf59.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf59.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
    buf81: ComputedBuffer
    buf81.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf81.users = [
        NodeUser(node=SchedulerNode(name='op82'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf82: ComputedBuffer
    buf82.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf82.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op59_op81_op82.snodes[0] =
op59: SchedulerNode(ComputedBuffer)
op59.writes = [MemoryDep('buf59', 0, {})]
op59.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 6*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf53', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf55', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf58', c0, {c0: ((s0 + 8)//9)})]
op59.met_dependencies = []
op59.outputs = [
    buf59: ComputedBuffer
    buf59.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf59.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op59.group.device = cuda:0
op59.group.iteration = (1, ((s0 + 8)//9))
op59.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf53_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf55_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf58_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf59_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op59_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 6*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf53', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf55', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf58', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf59', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op59_op81_op82.snodes[1] =
op81: SchedulerNode(ComputedBuffer)
op81.writes = [MemoryDep('buf81', c0, {c0: ((s0 + 8)//9)})]
op81.unmet_dependencies = [MemoryDep('buf3', c0 + 6*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op81.met_dependencies = []
op81.outputs = [
    buf81: ComputedBuffer
    buf81.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf81.users = [
        NodeUser(node=SchedulerNode(name='op82'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op81.group.device = cuda:0
op81.group.iteration = (((s0 + 8)//9), 1)
op81.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf81_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op81_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 6*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf81', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op59_op81_op82.snodes[2] =
op82: SchedulerNode(ComputedBuffer)
op82.writes = [MemoryDep('buf82', c0, {c0: ((s0 + 8)//9)})]
op82.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 6*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf81', c0, {c0: ((s0 + 8)//9)})]
op82.met_dependencies = []
op82.outputs = [
    buf82: ComputedBuffer
    buf82.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf82.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op82.group.device = cuda:0
op82.group.iteration = (((s0 + 8)//9), 1)
op82.sizes = ([((s0 + 8)//9)], [])
buf81_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf82_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op82_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = p0 + 6*(((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf81', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf82', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load


op65_op66: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op65_op66.writes = 
    [   MemoryDep('buf65', c0, {c0: ((s3 + 8)//9)}),
        MemoryDep('buf66', c0, {c0: ((s3 + 8)//9)})]
op65_op66.unmet_dependencies = [MemoryDep('buf64', c0, {c0: 5*(((s3 + 8)//9))})]
op65_op66.met_dependencies = []
op65_op66.outputs = [
    buf65: ComputedBuffer
    buf65.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf65.users = [NodeUser(node=SchedulerNode(name='op66'), can_inplace=True, is_weak=False)]
    buf66: ComputedBuffer
    buf66.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf66.users = [
        NodeUser(node=SchedulerNode(name='op67'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op65_op66.snodes[0] =
op65: SchedulerNode(ComputedBuffer)
op65.writes = [MemoryDep('buf65', c0, {c0: ((s3 + 8)//9)})]
op65.unmet_dependencies = [MemoryDep('buf64', c0, {c0: 5*(((s3 + 8)//9))})]
op65.met_dependencies = []
op65.outputs = [
    buf65: ComputedBuffer
    buf65.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
    buf65.users = [NodeUser(node=SchedulerNode(name='op66'), can_inplace=True, is_weak=False)]
]
op65.group.device = cuda:0
op65.group.iteration = (((s3 + 8)//9), 5)
op65.sizes = ([((s3 + 8)//9)], [5])
buf64_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1, 5], stride=[5, 5*(((s3 + 8)//9)), 1])
buf65_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
class op65_loop_body:
    var_ranges = {p0: ((s3 + 8)//9), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf64', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf65', get_index_1, reduction)
        return store_reduction
op65_op66.snodes[1] =
op66: SchedulerNode(ComputedBuffer)
op66.writes = [MemoryDep('buf66', c0, {c0: ((s3 + 8)//9)})]
op66.unmet_dependencies = [MemoryDep('buf65', c0, {c0: ((s3 + 8)//9)})]
op66.met_dependencies = []
op66.outputs = [
    buf66: ComputedBuffer
    buf66.layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
    buf66.users = [
        NodeUser(node=SchedulerNode(name='op67'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op66.group.device = cuda:0
op66.group.iteration = (((s3 + 8)//9), 1)
op66.sizes = ([((s3 + 8)//9)], [])
buf65_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, ((s3 + 8)//9)])
buf66_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
class op66_loop_body:
    var_ranges = {p0: ((s3 + 8)//9)}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf65', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf66', get_index_1, log, None)
        return store


op67_op79_op80: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode)
op67_op79_op80.writes = 
    [   MemoryDep('buf67', 0, {}),
        MemoryDep('buf79', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf80', c0, {c0: ((s0 + 8)//9)})]
op67_op79_op80.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 7*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf61', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf63', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf66', c0, {c0: ((s0 + 8)//9)})]
op67_op79_op80.met_dependencies = []
op67_op79_op80.outputs = [
    buf67: ComputedBuffer
    buf67.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf67.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
    buf79: ComputedBuffer
    buf79.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf79.users = [
        NodeUser(node=SchedulerNode(name='op80'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf80: ComputedBuffer
    buf80.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf80.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op67_op79_op80.snodes[0] =
op67: SchedulerNode(ComputedBuffer)
op67.writes = [MemoryDep('buf67', 0, {})]
op67.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 7*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf61', 262400*c0 + tmp0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf63', c0, {c0: ((s0 + 8)//9)}),
        MemoryDep('buf66', c0, {c0: ((s0 + 8)//9)})]
op67.met_dependencies = []
op67.outputs = [
    buf67: ComputedBuffer
    buf67.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf67.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op67.group.device = cuda:0
op67.group.iteration = (1, ((s0 + 8)//9))
op67.sizes = ([], [((s0 + 8)//9)])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf61_layout = FixedLayout('cuda:0', torch.bfloat16, size=[((s3 + 8)//9), 262400], stride=[262400, 1])
buf63_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf66_layout = FixedLayout('cuda:0', torch.float32, size=[((s3 + 8)//9), 1], stride=[1, 1])
buf67_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op67_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 7*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf61', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf63', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf66', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf67', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op67_op79_op80.snodes[1] =
op79: SchedulerNode(ComputedBuffer)
op79.writes = [MemoryDep('buf79', c0, {c0: ((s0 + 8)//9)})]
op79.unmet_dependencies = [MemoryDep('buf3', c0 + 7*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)})]
op79.met_dependencies = []
op79.outputs = [
    buf79: ComputedBuffer
    buf79.layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf79.users = [
        NodeUser(node=SchedulerNode(name='op80'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op79.group.device = cuda:0
op79.group.iteration = (((s0 + 8)//9), 1)
op79.sizes = ([((s0 + 8)//9)], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf79_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op79_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0 + 7*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf79', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op67_op79_op80.snodes[2] =
op80: SchedulerNode(ComputedBuffer)
op80.writes = [MemoryDep('buf80', c0, {c0: ((s0 + 8)//9)})]
op80.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 7*(((s0 + 8)//9)), {c0: ((s0 + 8)//9)}),
        MemoryDep('buf79', c0, {c0: ((s0 + 8)//9)})]
op80.met_dependencies = []
op80.outputs = [
    buf80: ComputedBuffer
    buf80.layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
    buf80.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op80.group.device = cuda:0
op80.group.iteration = (((s0 + 8)//9), 1)
op80.sizes = ([((s0 + 8)//9)], [])
buf79_layout = FixedLayout('cuda:0', torch.bool, size=[((s0 + 8)//9), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf80_layout = FixedLayout('cuda:0', torch.int64, size=[((s0 + 8)//9), 1], stride=[1, 1])
class op80_loop_body:
    var_ranges = {p0: ((s0 + 8)//9)}
    index0 = p0
    index1 = p0 + 7*(((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf79', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf80', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load


op73_op74: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op73_op74.writes = 
    [   MemoryDep('buf73', c0, {c0: s3 - 8*(((s3 + 8)//9))}),
        MemoryDep('buf74', c0, {c0: s3 - 8*(((s3 + 8)//9))})]
op73_op74.unmet_dependencies = [MemoryDep('buf72', c0, {c0: 5*s3 - 40*(((s3 + 8)//9))})]
op73_op74.met_dependencies = []
op73_op74.outputs = [
    buf73: ComputedBuffer
    buf73.layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, s3 - 8*(((s3 + 8)//9))])
    buf73.users = [NodeUser(node=SchedulerNode(name='op74'), can_inplace=True, is_weak=False)]
    buf74: ComputedBuffer
    buf74.layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
    buf74.users = [
        NodeUser(node=SchedulerNode(name='op75'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op73_op74.snodes[0] =
op73: SchedulerNode(ComputedBuffer)
op73.writes = [MemoryDep('buf73', c0, {c0: s3 - 8*(((s3 + 8)//9))})]
op73.unmet_dependencies = [MemoryDep('buf72', c0, {c0: 5*s3 - 40*(((s3 + 8)//9))})]
op73.met_dependencies = []
op73.outputs = [
    buf73: ComputedBuffer
    buf73.layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, s3 - 8*(((s3 + 8)//9))])
    buf73.users = [NodeUser(node=SchedulerNode(name='op74'), can_inplace=True, is_weak=False)]
]
op73.group.device = cuda:0
op73.group.iteration = (s3 - 8*(((s3 + 8)//9)), 5)
op73.sizes = ([s3 - 8*(((s3 + 8)//9))], [5])
buf72_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1, 5], stride=[5, 5*s3 - 40*(((s3 + 8)//9)), 1])
buf73_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, s3 - 8*(((s3 + 8)//9))])
class op73_loop_body:
    var_ranges = {p0: s3 - 8*(((s3 + 8)//9)), p1: 5}
    index0 = 5*p0 + p1
    index1 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf72', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf73', get_index_1, reduction)
        return store_reduction
op73_op74.snodes[1] =
op74: SchedulerNode(ComputedBuffer)
op74.writes = [MemoryDep('buf74', c0, {c0: s3 - 8*(((s3 + 8)//9))})]
op74.unmet_dependencies = [MemoryDep('buf73', c0, {c0: s3 - 8*(((s3 + 8)//9))})]
op74.met_dependencies = []
op74.outputs = [
    buf74: ComputedBuffer
    buf74.layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
    buf74.users = [
        NodeUser(node=SchedulerNode(name='op75'), can_inplace=False, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op74.group.device = cuda:0
op74.group.iteration = (s3 - 8*(((s3 + 8)//9)), 1)
op74.sizes = ([s3 - 8*(((s3 + 8)//9))], [])
buf73_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, s3 - 8*(((s3 + 8)//9))])
buf74_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
class op74_loop_body:
    var_ranges = {p0: s3 - 8*(((s3 + 8)//9))}
    index0 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf73', get_index)
        log = ops.log(load)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf74', get_index_1, log, None)
        return store


op75_op77_op78_op76_op95: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
op75_op77_op78_op76_op95.writes = 
    [   MemoryDep('buf75', 0, {}),
        MemoryDep('buf76', 0, {}),
        MemoryDep('buf77', c0, {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf78', c0, {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf95', 0, {})]
op75_op77_op78_op76_op95.unmet_dependencies = 
    [   MemoryDep('buf11', 0, {}),
        MemoryDep('buf19', 0, {}),
        MemoryDep('buf27', 0, {}),
        MemoryDep('buf3', c0 + 8*(((s0 + 8)//9)), {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf35', 0, {}),
        MemoryDep('buf43', 0, {}),
        MemoryDep('buf51', 0, {}),
        MemoryDep('buf59', 0, {}),
        MemoryDep('buf67', 0, {}),
        MemoryDep('buf69', 262400*c0 + tmp0, {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf71', c0, {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf74', c0, {c0: s0 - 8*(((s0 + 8)//9))})]
op75_op77_op78_op76_op95.met_dependencies = [MemoryDep('primals_8', 0, {})]
op75_op77_op78_op76_op95.outputs = [
    buf75: ComputedBuffer
    buf75.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf75.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
    buf77: ComputedBuffer
    buf77.layout = FixedLayout('cuda:0', torch.bool, size=[s0 - 8*(((s0 + 8)//9)), 1], stride=[1, 1])
    buf77.users = [
        NodeUser(node=SchedulerNode(name='op78'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf78: ComputedBuffer
    buf78.layout = FixedLayout('cuda:0', torch.int64, size=[s0 - 8*(((s0 + 8)//9)), 1], stride=[1, 1])
    buf78.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf76: ComputedBuffer
    buf76.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf76.users = [
        NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
    buf95: ComputedBuffer
    buf95.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf95.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op75_op77_op78_op76_op95.snodes[0] =
op75: SchedulerNode(ComputedBuffer)
op75.writes = [MemoryDep('buf75', 0, {})]
op75.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 8*(((s0 + 8)//9)), {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf69', 262400*c0 + tmp0, {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf71', c0, {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf74', c0, {c0: s0 - 8*(((s0 + 8)//9))})]
op75.met_dependencies = []
op75.outputs = [
    buf75: ComputedBuffer
    buf75.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf75.users = [NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False)]
]
op75.group.device = cuda:0
op75.group.iteration = (1, s0 - 8*(((s0 + 8)//9)))
op75.sizes = ([], [s0 - 8*(((s0 + 8)//9))])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf69_layout = FixedLayout('cuda:0', torch.bfloat16, size=[s3 - 8*(((s3 + 8)//9)), 262400], stride=[262400, 1])
buf71_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
buf74_layout = FixedLayout('cuda:0', torch.float32, size=[s3 - 8*(((s3 + 8)//9)), 1], stride=[1, 1])
buf75_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op75_loop_body:
    var_ranges = {p0: s0 - 8*(((s0 + 8)//9))}
    index0 = p0 + 8*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = indirect0 + 262400*p0
    index3 = p0
    index4 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_5, torch.int32)
        get_index_6 = self.get_index('index1')
        index_expr_5 = ops.index_expr(get_index_6, torch.int32)
        eq_1 = ops.eq(index_expr_4, index_expr_5)
        get_index_7 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_7, torch.int64)
        get_index_8 = self.get_index('index1')
        index_expr_7 = ops.index_expr(get_index_8, torch.int64)
        lt_1 = ops.lt(index_expr_6, index_expr_7)
        masked_subblock2 = self.masked_subblock2(lt_1, 0)
        get_index_9 = self.get_index('index0')
        load_1 = ops.load('buf1', get_index_9)
        where_2 = ops.where(lt_1, masked_subblock2, load_1)
        constant_2 = ops.constant(-100, torch.int64)
        where_3 = ops.where(eq_1, constant_2, where_2)
        constant_3 = ops.constant(-100, torch.int64)
        ne_1 = ops.ne(where_3, constant_3)
        get_index_10 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_10, torch.int32)
        get_index_11 = self.get_index('index1')
        index_expr_9 = ops.index_expr(get_index_11, torch.int32)
        eq_2 = ops.eq(index_expr_8, index_expr_9)
        get_index_12 = self.get_index('index0')
        index_expr_10 = ops.index_expr(get_index_12, torch.int64)
        get_index_13 = self.get_index('index1')
        index_expr_11 = ops.index_expr(get_index_13, torch.int64)
        lt_2 = ops.lt(index_expr_10, index_expr_11)
        masked_subblock3 = self.masked_subblock3(lt_2, 0)
        get_index_14 = self.get_index('index0')
        load_2 = ops.load('buf1', get_index_14)
        where_4 = ops.where(lt_2, masked_subblock3, load_2)
        constant_4 = ops.constant(-100, torch.int64)
        where_5 = ops.where(eq_2, constant_4, where_4)
        constant_5 = ops.constant(0, torch.int64)
        where_6 = ops.where(ne_1, where_5, constant_5)
        set_indirect0 = self.set_indirect0(where_6)
        get_index_15 = self.get_index('index2')
        load_3 = ops.load('buf69', get_index_15)
        constant_6 = ops.constant(0.03333333333333333, torch.bfloat16)
        mul = ops.mul(load_3, constant_6)
        tanh = ops.tanh(mul)
        to_dtype = ops.to_dtype(tanh, torch.float32, src_dtype = torch.bfloat16)
        constant_7 = ops.constant(1.0, torch.float32)
        mul_1 = ops.mul(to_dtype, constant_7)
        get_index_16 = self.get_index('index3')
        load_4 = ops.load('buf71', get_index_16)
        sub = ops.sub(mul_1, load_4)
        constant_8 = ops.constant(30.0, torch.float32)
        mul_2 = ops.mul(sub, constant_8)
        get_index_17 = self.get_index('index3')
        load_5 = ops.load('buf74', get_index_17)
        sub_1 = ops.sub(mul_2, load_5)
        neg = ops.neg(sub_1)
        constant_9 = ops.constant(0.0, torch.float32)
        where_7 = ops.where(ne, neg, constant_9)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', where_7)
        get_index_18 = self.get_index('index4')
        store_reduction = ops.store_reduction('buf75', get_index_18, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op75_op77_op78_op76_op95.snodes[1] =
op77: SchedulerNode(ComputedBuffer)
op77.writes = [MemoryDep('buf77', c0, {c0: s0 - 8*(((s0 + 8)//9))})]
op77.unmet_dependencies = [MemoryDep('buf3', c0 + 8*(((s0 + 8)//9)), {c0: s0 - 8*(((s0 + 8)//9))})]
op77.met_dependencies = []
op77.outputs = [
    buf77: ComputedBuffer
    buf77.layout = FixedLayout('cuda:0', torch.bool, size=[s0 - 8*(((s0 + 8)//9)), 1], stride=[1, 1])
    buf77.users = [
        NodeUser(node=SchedulerNode(name='op78'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op77.group.device = cuda:0
op77.group.iteration = (s0 - 8*(((s0 + 8)//9)), 1)
op77.sizes = ([s0 - 8*(((s0 + 8)//9))], [])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf77_layout = FixedLayout('cuda:0', torch.bool, size=[s0 - 8*(((s0 + 8)//9)), 1], stride=[1, 1])
class op77_loop_body:
    var_ranges = {p0: s0 - 8*(((s0 + 8)//9))}
    index0 = p0 + 8*(((s0 + 8)//9))
    index1 = s0 - 1
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        get_index_1 = self.get_index('index1')
        index_expr_1 = ops.index_expr(get_index_1, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_4 = self.get_index('index0')
        load = ops.load('buf1', get_index_4)
        where = ops.where(lt, masked_subblock1, load)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(-100, torch.int64)
        ne = ops.ne(where_1, constant_1)
        get_index_5 = self.get_index('index2')
        store = ops.store('buf77', get_index_5, ne, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        return load
op75_op77_op78_op76_op95.snodes[2] =
op78: SchedulerNode(ComputedBuffer)
op78.writes = [MemoryDep('buf78', c0, {c0: s0 - 8*(((s0 + 8)//9))})]
op78.unmet_dependencies = 
    [   MemoryDep('buf3', c0 + 8*(((s0 + 8)//9)), {c0: s0 - 8*(((s0 + 8)//9))}),
        MemoryDep('buf77', c0, {c0: s0 - 8*(((s0 + 8)//9))})]
op78.met_dependencies = []
op78.outputs = [
    buf78: ComputedBuffer
    buf78.layout = FixedLayout('cuda:0', torch.int64, size=[s0 - 8*(((s0 + 8)//9)), 1], stride=[1, 1])
    buf78.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op78.group.device = cuda:0
op78.group.iteration = (s0 - 8*(((s0 + 8)//9)), 1)
op78.sizes = ([s0 - 8*(((s0 + 8)//9))], [])
buf77_layout = FixedLayout('cuda:0', torch.bool, size=[s0 - 8*(((s0 + 8)//9)), 1], stride=[1, 1])
buf3_layout = MutationLayoutSHOULDREMOVE('cuda:0', torch.int64, size=[1, s0 - 1], stride=[s0, 1])
buf78_layout = FixedLayout('cuda:0', torch.int64, size=[s0 - 8*(((s0 + 8)//9)), 1], stride=[1, 1])
class op78_loop_body:
    var_ranges = {p0: s0 - 8*(((s0 + 8)//9))}
    index0 = p0
    index1 = p0 + 8*(((s0 + 8)//9))
    index2 = s0 - 1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf77', get_index)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int32)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int32)
        eq = ops.eq(index_expr, index_expr_1)
        get_index_3 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_3, torch.int64)
        get_index_4 = self.get_index('index2')
        index_expr_3 = ops.index_expr(get_index_4, torch.int64)
        lt = ops.lt(index_expr_2, index_expr_3)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        get_index_5 = self.get_index('index1')
        load_1 = ops.load('buf1', get_index_5)
        where = ops.where(lt, masked_subblock1, load_1)
        constant = ops.constant(-100, torch.int64)
        where_1 = ops.where(eq, constant, where)
        constant_1 = ops.constant(0, torch.int64)
        where_2 = ops.where(load, where_1, constant_1)
        get_index_6 = self.get_index('index0')
        store = ops.store('buf78', get_index_6, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf1', get_index)
        return load
op75_op77_op78_op76_op95.snodes[3] =
op76: SchedulerNode(ComputedBuffer)
op76.writes = [MemoryDep('buf76', 0, {})]
op76.unmet_dependencies = []
op76.met_dependencies = [MemoryDep('primals_8', 0, {})]
op76.outputs = [
    buf76: ComputedBuffer
    buf76.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf76.users = [
        NodeUser(node=SchedulerNode(name='op95'), can_inplace=True, is_weak=False),
        NodeUser(node=OUTPUT, can_inplace=False, is_weak=False),
    ]
]
op76.group.device = cuda:0
op76.group.iteration = (1, 1)
op76.sizes = ([], [])
primals_8_layout = FixedLayout('cuda:0', torch.int64, size=[], stride=[])
buf76_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op76_loop_body:
    var_ranges = {}
    index0 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_8', get_index)
        to_dtype = ops.to_dtype(load, torch.float32, src_dtype = torch.int64)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf76', get_index_1, to_dtype, None)
        return store
op75_op77_op78_op76_op95.snodes[4] =
op95: SchedulerNode(ComputedBuffer)
op95.writes = [MemoryDep('buf95', 0, {})]
op95.unmet_dependencies = 
    [   MemoryDep('buf11', 0, {}),
        MemoryDep('buf19', 0, {}),
        MemoryDep('buf27', 0, {}),
        MemoryDep('buf35', 0, {}),
        MemoryDep('buf43', 0, {}),
        MemoryDep('buf51', 0, {}),
        MemoryDep('buf59', 0, {}),
        MemoryDep('buf67', 0, {}),
        MemoryDep('buf75', 0, {}),
        MemoryDep('buf76', 0, {})]
op95.met_dependencies = []
op95.outputs = [
    buf95: ComputedBuffer
    buf95.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf95.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op95.group.device = cuda:0
op95.group.iteration = (1, 1)
op95.sizes = ([], [])
buf11_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf19_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf27_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf35_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf43_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf51_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf59_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf67_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf75_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf76_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf95_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op95_loop_body:
    var_ranges = {}
    index0 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf11', get_index)
        constant = ops.constant(0.0, torch.float32)
        add = ops.add(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf19', get_index_1)
        add_1 = ops.add(add, load_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('buf27', get_index_2)
        add_2 = ops.add(add_1, load_2)
        get_index_3 = self.get_index('index0')
        load_3 = ops.load('buf35', get_index_3)
        add_3 = ops.add(add_2, load_3)
        get_index_4 = self.get_index('index0')
        load_4 = ops.load('buf43', get_index_4)
        add_4 = ops.add(add_3, load_4)
        get_index_5 = self.get_index('index0')
        load_5 = ops.load('buf51', get_index_5)
        add_5 = ops.add(add_4, load_5)
        get_index_6 = self.get_index('index0')
        load_6 = ops.load('buf59', get_index_6)
        add_6 = ops.add(add_5, load_6)
        get_index_7 = self.get_index('index0')
        load_7 = ops.load('buf67', get_index_7)
        add_7 = ops.add(add_6, load_7)
        get_index_8 = self.get_index('index0')
        load_8 = ops.load('buf75', get_index_8)
        add_8 = ops.add(add_7, load_8)
        get_index_9 = self.get_index('index0')
        load_9 = ops.load('buf76', get_index_9)
        truediv = ops.truediv(add_8, load_9)
        get_index_10 = self.get_index('index0')
        store = ops.store('buf95', get_index_10, truediv, None)
        return store


